2025-12-12 19:44:00,114 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-12 19:44:00,115 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-12 19:44:00,155 - _trace.py:47 - DEBUG - connect_tcp.started host='raw.githubusercontent.com' port=443 local_address=None timeout=5 socket_options=None
2025-12-12 19:44:00,227 - _trace.py:47 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1322c82c0>
2025-12-12 19:44:00,227 - _trace.py:47 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1322868d0> server_hostname='raw.githubusercontent.com' timeout=5
2025-12-12 19:44:00,298 - _trace.py:47 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x131df2c90>
2025-12-12 19:44:00,299 - _trace.py:47 - DEBUG - send_request_headers.started request=<Request [b'GET']>
2025-12-12 19:44:00,299 - _trace.py:47 - DEBUG - send_request_headers.complete
2025-12-12 19:44:00,299 - _trace.py:47 - DEBUG - send_request_body.started request=<Request [b'GET']>
2025-12-12 19:44:00,299 - _trace.py:47 - DEBUG - send_request_body.complete
2025-12-12 19:44:00,299 - _trace.py:47 - DEBUG - receive_response_headers.started request=<Request [b'GET']>
2025-12-12 19:44:00,341 - _trace.py:47 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Connection', b'keep-alive'), (b'Content-Length', b'55842'), (b'Cache-Control', b'max-age=300'), (b'Content-Security-Policy', b"default-src 'none'; style-src 'unsafe-inline'; sandbox"), (b'Content-Type', b'text/plain; charset=utf-8'), (b'ETag', b'W/"3e61c1d6e72c1b8eb8c9c5a8001a6cd74f187355ba209bc10078eac083452c3f"'), (b'Strict-Transport-Security', b'max-age=31536000'), (b'X-Content-Type-Options', b'nosniff'), (b'X-Frame-Options', b'deny'), (b'X-XSS-Protection', b'1; mode=block'), (b'X-GitHub-Request-Id', b'48BD:AA3DE:EAF52:1BA624:693C81AA'), (b'Content-Encoding', b'gzip'), (b'Accept-Ranges', b'bytes'), (b'Date', b'Fri, 12 Dec 2025 22:44:00 GMT'), (b'Via', b'1.1 varnish'), (b'X-Served-By', b'cache-gru-sbsp2090080-GRU'), (b'X-Cache', b'HIT'), (b'X-Cache-Hits', b'2'), (b'X-Timer', b'S1765579440.419692,VS0,VE0'), (b'Vary', b'Authorization,Accept-Encoding'), (b'Access-Control-Allow-Origin', b'*'), (b'Cross-Origin-Resource-Policy', b'cross-origin'), (b'X-Fastly-Request-ID', b'dc0f51d9deebdc4110cf5658ec7bfd52d6750eaa'), (b'Expires', b'Fri, 12 Dec 2025 22:49:00 GMT'), (b'Source-Age', b'95')])
2025-12-12 19:44:00,341 - _trace.py:47 - DEBUG - receive_response_body.started request=<Request [b'GET']>
2025-12-12 19:44:00,374 - _trace.py:47 - DEBUG - receive_response_body.complete
2025-12-12 19:44:00,375 - _trace.py:47 - DEBUG - response_closed.started
2025-12-12 19:44:00,375 - _trace.py:47 - DEBUG - response_closed.complete
2025-12-12 19:44:00,375 - _trace.py:47 - DEBUG - close.started
2025-12-12 19:44:00,375 - _trace.py:47 - DEBUG - close.complete
2025-12-12 19:44:00,831 - litellm_logging.py:179 - DEBUG - [Non-Blocking] Unable to import GenericAPILogger - LiteLLM Enterprise Feature - No module named 'litellm_enterprise'
2025-12-12 19:44:00,968 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-12 19:44:00,968 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-12 19:44:00,975 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-12 19:44:00,975 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-12 19:44:00,980 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-12 19:44:00,980 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-12 19:44:01,343 - plugin_manager.py:96 - INFO - Plugin 'logging_plugin' registered.
2025-12-12 19:44:01,343 - plugin_manager.py:96 - INFO - Plugin 'rubric_guardrail' registered.
2025-12-12 19:44:01,573 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-12 19:44:01,573 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-12 19:44:01,574 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-12 19:44:01,577 - utils.py:350 - DEBUG - 

2025-12-12 19:44:01,577 - utils.py:350 - DEBUG - [92mRequest to litellm:[0m
2025-12-12 19:44:01,577 - utils.py:350 - DEBUG - [92mlitellm.completion(model='', messages=[{'role': 'user', 'content': 'prompt'}], temperature=0.4, max_tokens=512, timeout=30)[0m
2025-12-12 19:44:01,577 - utils.py:350 - DEBUG - 

2025-12-12 19:44:01,577 - litellm_logging.py:474 - DEBUG - self.optional_params: {}
2025-12-12 19:44:01,577 - utils.py:350 - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-12-12 19:44:01,585 - litellm_logging.py:2455 - DEBUG - Logging Details LiteLLM-Failure Call: []
2025-12-12 19:44:01,701 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-12 19:44:01,702 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-12 19:44:01,702 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-12 19:44:01,810 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-12 19:44:01,839 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-12 19:46:13,402 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-12 19:46:13,403 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-12 19:46:13,444 - _trace.py:47 - DEBUG - connect_tcp.started host='raw.githubusercontent.com' port=443 local_address=None timeout=5 socket_options=None
2025-12-12 19:46:13,480 - _trace.py:47 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12c1c8290>
2025-12-12 19:46:13,480 - _trace.py:47 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x12c1868d0> server_hostname='raw.githubusercontent.com' timeout=5
2025-12-12 19:46:13,519 - _trace.py:47 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12bc53ec0>
2025-12-12 19:46:13,519 - _trace.py:47 - DEBUG - send_request_headers.started request=<Request [b'GET']>
2025-12-12 19:46:13,520 - _trace.py:47 - DEBUG - send_request_headers.complete
2025-12-12 19:46:13,520 - _trace.py:47 - DEBUG - send_request_body.started request=<Request [b'GET']>
2025-12-12 19:46:13,520 - _trace.py:47 - DEBUG - send_request_body.complete
2025-12-12 19:46:13,520 - _trace.py:47 - DEBUG - receive_response_headers.started request=<Request [b'GET']>
2025-12-12 19:46:13,556 - _trace.py:47 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Connection', b'keep-alive'), (b'Content-Length', b'55842'), (b'Cache-Control', b'max-age=300'), (b'Content-Security-Policy', b"default-src 'none'; style-src 'unsafe-inline'; sandbox"), (b'Content-Type', b'text/plain; charset=utf-8'), (b'ETag', b'W/"3e61c1d6e72c1b8eb8c9c5a8001a6cd74f187355ba209bc10078eac083452c3f"'), (b'Strict-Transport-Security', b'max-age=31536000'), (b'X-Content-Type-Options', b'nosniff'), (b'X-Frame-Options', b'deny'), (b'X-XSS-Protection', b'1; mode=block'), (b'X-GitHub-Request-Id', b'48BD:AA3DE:EAF52:1BA624:693C81AA'), (b'Content-Encoding', b'gzip'), (b'Accept-Ranges', b'bytes'), (b'Date', b'Fri, 12 Dec 2025 22:46:13 GMT'), (b'Via', b'1.1 varnish'), (b'X-Served-By', b'cache-gru-sbsp2090038-GRU'), (b'X-Cache', b'HIT'), (b'X-Cache-Hits', b'3'), (b'X-Timer', b'S1765579574.647258,VS0,VE0'), (b'Vary', b'Authorization,Accept-Encoding'), (b'Access-Control-Allow-Origin', b'*'), (b'Cross-Origin-Resource-Policy', b'cross-origin'), (b'X-Fastly-Request-ID', b'68991b78ca696ca72fb4a0b6f363ffe019e28d59'), (b'Expires', b'Fri, 12 Dec 2025 22:51:13 GMT'), (b'Source-Age', b'228')])
2025-12-12 19:46:13,556 - _trace.py:47 - DEBUG - receive_response_body.started request=<Request [b'GET']>
2025-12-12 19:46:13,591 - _trace.py:47 - DEBUG - receive_response_body.complete
2025-12-12 19:46:13,591 - _trace.py:47 - DEBUG - response_closed.started
2025-12-12 19:46:13,591 - _trace.py:47 - DEBUG - response_closed.complete
2025-12-12 19:46:13,592 - _trace.py:47 - DEBUG - close.started
2025-12-12 19:46:13,592 - _trace.py:47 - DEBUG - close.complete
2025-12-12 19:46:14,034 - litellm_logging.py:179 - DEBUG - [Non-Blocking] Unable to import GenericAPILogger - LiteLLM Enterprise Feature - No module named 'litellm_enterprise'
2025-12-12 19:46:14,156 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-12 19:46:14,156 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-12 19:46:14,162 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-12 19:46:14,162 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-12 19:46:14,167 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-12 19:46:14,167 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-12 19:46:14,435 - plugin_manager.py:96 - INFO - Plugin 'logging_plugin' registered.
2025-12-12 19:46:14,435 - plugin_manager.py:96 - INFO - Plugin 'rubric_guardrail' registered.
2025-12-12 19:46:14,671 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-12 19:46:14,672 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-12 19:46:14,672 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-12 19:46:14,677 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-12 19:46:14,677 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-12 19:46:14,677 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-12 19:46:14,772 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-12 19:46:14,789 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-12 19:47:31,473 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-12 19:47:31,474 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-12 19:47:31,512 - _trace.py:47 - DEBUG - connect_tcp.started host='raw.githubusercontent.com' port=443 local_address=None timeout=5 socket_options=None
2025-12-12 19:47:31,548 - _trace.py:47 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1133c82f0>
2025-12-12 19:47:31,548 - _trace.py:47 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x113386850> server_hostname='raw.githubusercontent.com' timeout=5
2025-12-12 19:47:31,623 - _trace.py:47 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x112daa150>
2025-12-12 19:47:31,623 - _trace.py:47 - DEBUG - send_request_headers.started request=<Request [b'GET']>
2025-12-12 19:47:31,623 - _trace.py:47 - DEBUG - send_request_headers.complete
2025-12-12 19:47:31,623 - _trace.py:47 - DEBUG - send_request_body.started request=<Request [b'GET']>
2025-12-12 19:47:31,623 - _trace.py:47 - DEBUG - send_request_body.complete
2025-12-12 19:47:31,623 - _trace.py:47 - DEBUG - receive_response_headers.started request=<Request [b'GET']>
2025-12-12 19:47:31,678 - _trace.py:47 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Connection', b'keep-alive'), (b'Content-Length', b'55842'), (b'Cache-Control', b'max-age=300'), (b'Content-Security-Policy', b"default-src 'none'; style-src 'unsafe-inline'; sandbox"), (b'Content-Type', b'text/plain; charset=utf-8'), (b'ETag', b'W/"3e61c1d6e72c1b8eb8c9c5a8001a6cd74f187355ba209bc10078eac083452c3f"'), (b'Strict-Transport-Security', b'max-age=31536000'), (b'X-Content-Type-Options', b'nosniff'), (b'X-Frame-Options', b'deny'), (b'X-XSS-Protection', b'1; mode=block'), (b'X-GitHub-Request-Id', b'48BD:AA3DE:EAF52:1BA624:693C81AA'), (b'Content-Encoding', b'gzip'), (b'Accept-Ranges', b'bytes'), (b'Date', b'Fri, 12 Dec 2025 22:47:31 GMT'), (b'Via', b'1.1 varnish'), (b'X-Served-By', b'cache-gru-sbsp2090069-GRU'), (b'X-Cache', b'HIT'), (b'X-Cache-Hits', b'1'), (b'X-Timer', b'S1765579652.764805,VS0,VE6'), (b'Vary', b'Authorization,Accept-Encoding'), (b'Access-Control-Allow-Origin', b'*'), (b'Cross-Origin-Resource-Policy', b'cross-origin'), (b'X-Fastly-Request-ID', b'95c64e04e591c3c893eccbf92e546d522ba74048'), (b'Expires', b'Fri, 12 Dec 2025 22:52:31 GMT'), (b'Source-Age', b'5')])
2025-12-12 19:47:31,679 - _trace.py:47 - DEBUG - receive_response_body.started request=<Request [b'GET']>
2025-12-12 19:47:31,708 - _trace.py:47 - DEBUG - receive_response_body.complete
2025-12-12 19:47:31,708 - _trace.py:47 - DEBUG - response_closed.started
2025-12-12 19:47:31,708 - _trace.py:47 - DEBUG - response_closed.complete
2025-12-12 19:47:31,708 - _trace.py:47 - DEBUG - close.started
2025-12-12 19:47:31,708 - _trace.py:47 - DEBUG - close.complete
2025-12-12 19:47:32,162 - litellm_logging.py:179 - DEBUG - [Non-Blocking] Unable to import GenericAPILogger - LiteLLM Enterprise Feature - No module named 'litellm_enterprise'
2025-12-12 19:47:32,284 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-12 19:47:32,284 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-12 19:47:32,290 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-12 19:47:32,290 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-12 19:47:32,295 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-12 19:47:32,295 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-12 19:47:32,558 - plugin_manager.py:96 - INFO - Plugin 'logging_plugin' registered.
2025-12-12 19:47:32,558 - plugin_manager.py:96 - INFO - Plugin 'rubric_guardrail' registered.
2025-12-12 19:47:32,724 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-12 19:47:32,725 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-12 19:47:32,725 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-12 19:47:32,729 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-12 19:47:32,729 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-12 19:47:32,730 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-12 19:47:32,825 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-12 19:47:32,841 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-12 19:47:53,356 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-12 19:47:53,357 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-12 19:47:53,394 - _trace.py:47 - DEBUG - connect_tcp.started host='raw.githubusercontent.com' port=443 local_address=None timeout=5 socket_options=None
2025-12-12 19:47:53,425 - _trace.py:47 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x137ecc290>
2025-12-12 19:47:53,425 - _trace.py:47 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x137e867d0> server_hostname='raw.githubusercontent.com' timeout=5
2025-12-12 19:47:53,466 - _trace.py:47 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x137cc3ec0>
2025-12-12 19:47:53,466 - _trace.py:47 - DEBUG - send_request_headers.started request=<Request [b'GET']>
2025-12-12 19:47:53,466 - _trace.py:47 - DEBUG - send_request_headers.complete
2025-12-12 19:47:53,466 - _trace.py:47 - DEBUG - send_request_body.started request=<Request [b'GET']>
2025-12-12 19:47:53,466 - _trace.py:47 - DEBUG - send_request_body.complete
2025-12-12 19:47:53,466 - _trace.py:47 - DEBUG - receive_response_headers.started request=<Request [b'GET']>
2025-12-12 19:47:53,502 - _trace.py:47 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Connection', b'keep-alive'), (b'Content-Length', b'55842'), (b'Cache-Control', b'max-age=300'), (b'Content-Security-Policy', b"default-src 'none'; style-src 'unsafe-inline'; sandbox"), (b'Content-Type', b'text/plain; charset=utf-8'), (b'ETag', b'W/"3e61c1d6e72c1b8eb8c9c5a8001a6cd74f187355ba209bc10078eac083452c3f"'), (b'Strict-Transport-Security', b'max-age=31536000'), (b'X-Content-Type-Options', b'nosniff'), (b'X-Frame-Options', b'deny'), (b'X-XSS-Protection', b'1; mode=block'), (b'X-GitHub-Request-Id', b'48BD:AA3DE:EAF52:1BA624:693C81AA'), (b'Content-Encoding', b'gzip'), (b'Accept-Ranges', b'bytes'), (b'Date', b'Fri, 12 Dec 2025 22:47:53 GMT'), (b'Via', b'1.1 varnish'), (b'X-Served-By', b'cache-gru-sbsp2090032-GRU'), (b'X-Cache', b'HIT'), (b'X-Cache-Hits', b'1'), (b'X-Timer', b'S1765579674.593968,VS0,VE2'), (b'Vary', b'Authorization,Accept-Encoding'), (b'Access-Control-Allow-Origin', b'*'), (b'Cross-Origin-Resource-Policy', b'cross-origin'), (b'X-Fastly-Request-ID', b'2772114fd13c663e0f8623433f3c1d74b1daa8d4'), (b'Expires', b'Fri, 12 Dec 2025 22:52:53 GMT'), (b'Source-Age', b'27')])
2025-12-12 19:47:53,502 - _trace.py:47 - DEBUG - receive_response_body.started request=<Request [b'GET']>
2025-12-12 19:47:53,538 - _trace.py:47 - DEBUG - receive_response_body.complete
2025-12-12 19:47:53,538 - _trace.py:47 - DEBUG - response_closed.started
2025-12-12 19:47:53,538 - _trace.py:47 - DEBUG - response_closed.complete
2025-12-12 19:47:53,538 - _trace.py:47 - DEBUG - close.started
2025-12-12 19:47:53,538 - _trace.py:47 - DEBUG - close.complete
2025-12-12 19:47:53,995 - litellm_logging.py:179 - DEBUG - [Non-Blocking] Unable to import GenericAPILogger - LiteLLM Enterprise Feature - No module named 'litellm_enterprise'
2025-12-12 19:47:54,119 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-12 19:47:54,119 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-12 19:47:54,125 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-12 19:47:54,125 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-12 19:47:54,130 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-12 19:47:54,130 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-12 19:47:54,399 - plugin_manager.py:96 - INFO - Plugin 'logging_plugin' registered.
2025-12-12 19:47:54,399 - plugin_manager.py:96 - INFO - Plugin 'rubric_guardrail' registered.
2025-12-12 19:47:54,433 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-12 19:47:54,434 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-12 19:47:54,434 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-12 19:47:54,438 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-12 19:47:54,439 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-12 19:47:54,439 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-12 19:47:54,575 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-12 19:47:54,576 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-13 07:32:57,703 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-13 07:32:57,704 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-13 07:32:57,774 - _trace.py:47 - DEBUG - connect_tcp.started host='raw.githubusercontent.com' port=443 local_address=None timeout=5 socket_options=None
2025-12-13 07:32:57,828 - _trace.py:47 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x156f54ec0>
2025-12-13 07:32:57,828 - _trace.py:47 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x156f48cd0> server_hostname='raw.githubusercontent.com' timeout=5
2025-12-13 07:32:57,868 - _trace.py:47 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x156f54e00>
2025-12-13 07:32:57,869 - _trace.py:47 - DEBUG - send_request_headers.started request=<Request [b'GET']>
2025-12-13 07:32:57,869 - _trace.py:47 - DEBUG - send_request_headers.complete
2025-12-13 07:32:57,869 - _trace.py:47 - DEBUG - send_request_body.started request=<Request [b'GET']>
2025-12-13 07:32:57,869 - _trace.py:47 - DEBUG - send_request_body.complete
2025-12-13 07:32:57,869 - _trace.py:47 - DEBUG - receive_response_headers.started request=<Request [b'GET']>
2025-12-13 07:32:57,903 - _trace.py:47 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Connection', b'keep-alive'), (b'Content-Length', b'55842'), (b'Cache-Control', b'max-age=300'), (b'Content-Security-Policy', b"default-src 'none'; style-src 'unsafe-inline'; sandbox"), (b'Content-Type', b'text/plain; charset=utf-8'), (b'ETag', b'W/"3e61c1d6e72c1b8eb8c9c5a8001a6cd74f187355ba209bc10078eac083452c3f"'), (b'Strict-Transport-Security', b'max-age=31536000'), (b'X-Content-Type-Options', b'nosniff'), (b'X-Frame-Options', b'deny'), (b'X-XSS-Protection', b'1; mode=block'), (b'X-GitHub-Request-Id', b'48BD:AA3DE:EAF52:1BA624:693C81AA'), (b'Content-Encoding', b'gzip'), (b'Accept-Ranges', b'bytes'), (b'Date', b'Sat, 13 Dec 2025 10:32:57 GMT'), (b'Via', b'1.1 varnish'), (b'X-Served-By', b'cache-gru-sbsp2090027-GRU'), (b'X-Cache', b'HIT'), (b'X-Cache-Hits', b'3'), (b'X-Timer', b'S1765621978.886398,VS0,VE0'), (b'Vary', b'Authorization,Accept-Encoding'), (b'Access-Control-Allow-Origin', b'*'), (b'Cross-Origin-Resource-Policy', b'cross-origin'), (b'X-Fastly-Request-ID', b'706b74fed9d384f76435bfe4500c23f953fe18e6'), (b'Expires', b'Sat, 13 Dec 2025 10:37:57 GMT'), (b'Source-Age', b'243')])
2025-12-13 07:32:57,903 - _trace.py:47 - DEBUG - receive_response_body.started request=<Request [b'GET']>
2025-12-13 07:32:57,934 - _trace.py:47 - DEBUG - receive_response_body.complete
2025-12-13 07:32:57,934 - _trace.py:47 - DEBUG - response_closed.started
2025-12-13 07:32:57,934 - _trace.py:47 - DEBUG - response_closed.complete
2025-12-13 07:32:57,934 - _trace.py:47 - DEBUG - close.started
2025-12-13 07:32:57,934 - _trace.py:47 - DEBUG - close.complete
2025-12-13 07:32:58,653 - litellm_logging.py:179 - DEBUG - [Non-Blocking] Unable to import GenericAPILogger - LiteLLM Enterprise Feature - No module named 'litellm_enterprise'
2025-12-13 07:32:58,850 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-13 07:32:58,850 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-13 07:32:58,861 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-13 07:32:58,861 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-13 07:32:58,869 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-13 07:32:58,869 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-13 07:32:59,337 - plugin_manager.py:96 - INFO - Plugin 'logging_plugin' registered.
2025-12-13 07:32:59,337 - plugin_manager.py:96 - INFO - Plugin 'rubric_guardrail' registered.
2025-12-13 07:32:59,337 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-13 07:54:36,892 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-13 07:54:36,893 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-13 07:54:36,964 - _trace.py:47 - DEBUG - connect_tcp.started host='raw.githubusercontent.com' port=443 local_address=None timeout=5 socket_options=None
2025-12-13 07:54:36,996 - _trace.py:47 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1288e8b90>
2025-12-13 07:54:36,996 - _trace.py:47 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x128c4cbd0> server_hostname='raw.githubusercontent.com' timeout=5
2025-12-13 07:54:37,032 - _trace.py:47 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x128883560>
2025-12-13 07:54:37,032 - _trace.py:47 - DEBUG - send_request_headers.started request=<Request [b'GET']>
2025-12-13 07:54:37,033 - _trace.py:47 - DEBUG - send_request_headers.complete
2025-12-13 07:54:37,033 - _trace.py:47 - DEBUG - send_request_body.started request=<Request [b'GET']>
2025-12-13 07:54:37,033 - _trace.py:47 - DEBUG - send_request_body.complete
2025-12-13 07:54:37,033 - _trace.py:47 - DEBUG - receive_response_headers.started request=<Request [b'GET']>
2025-12-13 07:54:37,060 - _trace.py:47 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Connection', b'keep-alive'), (b'Content-Length', b'55842'), (b'Cache-Control', b'max-age=300'), (b'Content-Security-Policy', b"default-src 'none'; style-src 'unsafe-inline'; sandbox"), (b'Content-Type', b'text/plain; charset=utf-8'), (b'ETag', b'W/"3e61c1d6e72c1b8eb8c9c5a8001a6cd74f187355ba209bc10078eac083452c3f"'), (b'Strict-Transport-Security', b'max-age=31536000'), (b'X-Content-Type-Options', b'nosniff'), (b'X-Frame-Options', b'deny'), (b'X-XSS-Protection', b'1; mode=block'), (b'X-GitHub-Request-Id', b'48BD:AA3DE:EAF52:1BA624:693C81AA'), (b'Content-Encoding', b'gzip'), (b'Accept-Ranges', b'bytes'), (b'Date', b'Sat, 13 Dec 2025 10:54:37 GMT'), (b'Via', b'1.1 varnish'), (b'X-Served-By', b'cache-gru-sbsp2090067-GRU'), (b'X-Cache', b'HIT'), (b'X-Cache-Hits', b'1'), (b'X-Timer', b'S1765623277.067391,VS0,VE1'), (b'Vary', b'Authorization,Accept-Encoding'), (b'Access-Control-Allow-Origin', b'*'), (b'Cross-Origin-Resource-Policy', b'cross-origin'), (b'X-Fastly-Request-ID', b'6004f099b6a62616162d8aaebcce04dac38d005a'), (b'Expires', b'Sat, 13 Dec 2025 10:59:37 GMT'), (b'Source-Age', b'38')])
2025-12-13 07:54:37,061 - _trace.py:47 - DEBUG - receive_response_body.started request=<Request [b'GET']>
2025-12-13 07:54:37,090 - _trace.py:47 - DEBUG - receive_response_body.complete
2025-12-13 07:54:37,090 - _trace.py:47 - DEBUG - response_closed.started
2025-12-13 07:54:37,090 - _trace.py:47 - DEBUG - response_closed.complete
2025-12-13 07:54:37,090 - _trace.py:47 - DEBUG - close.started
2025-12-13 07:54:37,090 - _trace.py:47 - DEBUG - close.complete
2025-12-13 07:54:37,756 - litellm_logging.py:179 - DEBUG - [Non-Blocking] Unable to import GenericAPILogger - LiteLLM Enterprise Feature - No module named 'litellm_enterprise'
2025-12-13 07:54:37,927 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-13 07:54:37,928 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-13 07:54:37,938 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-13 07:54:37,938 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-13 07:54:37,946 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-13 07:54:37,946 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-13 07:54:38,461 - plugin_manager.py:96 - INFO - Plugin 'logging_plugin' registered.
2025-12-13 07:54:38,461 - plugin_manager.py:96 - INFO - Plugin 'rubric_guardrail' registered.
2025-12-13 07:54:38,461 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-13 08:13:43,044 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-13 08:13:43,048 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-13 08:13:43,110 - _trace.py:47 - DEBUG - connect_tcp.started host='raw.githubusercontent.com' port=443 local_address=None timeout=5 socket_options=None
2025-12-13 08:13:43,159 - _trace.py:47 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x135c4d790>
2025-12-13 08:13:43,160 - _trace.py:47 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x135c50bd0> server_hostname='raw.githubusercontent.com' timeout=5
2025-12-13 08:13:43,197 - _trace.py:47 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x135c4d6a0>
2025-12-13 08:13:43,197 - _trace.py:47 - DEBUG - send_request_headers.started request=<Request [b'GET']>
2025-12-13 08:13:43,197 - _trace.py:47 - DEBUG - send_request_headers.complete
2025-12-13 08:13:43,197 - _trace.py:47 - DEBUG - send_request_body.started request=<Request [b'GET']>
2025-12-13 08:13:43,197 - _trace.py:47 - DEBUG - send_request_body.complete
2025-12-13 08:13:43,197 - _trace.py:47 - DEBUG - receive_response_headers.started request=<Request [b'GET']>
2025-12-13 08:13:43,228 - _trace.py:47 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Connection', b'keep-alive'), (b'Content-Length', b'55842'), (b'Cache-Control', b'max-age=300'), (b'Content-Security-Policy', b"default-src 'none'; style-src 'unsafe-inline'; sandbox"), (b'Content-Type', b'text/plain; charset=utf-8'), (b'ETag', b'W/"3e61c1d6e72c1b8eb8c9c5a8001a6cd74f187355ba209bc10078eac083452c3f"'), (b'Strict-Transport-Security', b'max-age=31536000'), (b'X-Content-Type-Options', b'nosniff'), (b'X-Frame-Options', b'deny'), (b'X-XSS-Protection', b'1; mode=block'), (b'X-GitHub-Request-Id', b'48BD:AA3DE:EAF52:1BA624:693C81AA'), (b'Content-Encoding', b'gzip'), (b'Accept-Ranges', b'bytes'), (b'Date', b'Sat, 13 Dec 2025 11:13:43 GMT'), (b'Via', b'1.1 varnish'), (b'X-Served-By', b'cache-gru-sbsp2090072-GRU'), (b'X-Cache', b'HIT'), (b'X-Cache-Hits', b'7'), (b'X-Timer', b'S1765624423.238328,VS0,VE0'), (b'Vary', b'Authorization,Accept-Encoding'), (b'Access-Control-Allow-Origin', b'*'), (b'Cross-Origin-Resource-Policy', b'cross-origin'), (b'X-Fastly-Request-ID', b'cd6d93128500b6f99a42d094254a3d64c08fa40c'), (b'Expires', b'Sat, 13 Dec 2025 11:18:43 GMT'), (b'Source-Age', b'283')])
2025-12-13 08:13:43,229 - _trace.py:47 - DEBUG - receive_response_body.started request=<Request [b'GET']>
2025-12-13 08:13:43,269 - _trace.py:47 - DEBUG - receive_response_body.complete
2025-12-13 08:13:43,269 - _trace.py:47 - DEBUG - response_closed.started
2025-12-13 08:13:43,269 - _trace.py:47 - DEBUG - response_closed.complete
2025-12-13 08:13:43,269 - _trace.py:47 - DEBUG - close.started
2025-12-13 08:13:43,269 - _trace.py:47 - DEBUG - close.complete
2025-12-13 08:13:43,927 - litellm_logging.py:179 - DEBUG - [Non-Blocking] Unable to import GenericAPILogger - LiteLLM Enterprise Feature - No module named 'litellm_enterprise'
2025-12-13 08:13:44,109 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-13 08:13:44,109 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-13 08:13:44,120 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-13 08:13:44,120 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-13 08:13:44,128 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-13 08:13:44,129 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-13 08:13:44,588 - plugin_manager.py:96 - INFO - Plugin 'logging_plugin' registered.
2025-12-13 08:13:44,588 - plugin_manager.py:96 - INFO - Plugin 'rubric_guardrail' registered.
2025-12-13 08:13:44,588 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-13 08:13:44,589 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-13 08:38:53,049 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-13 08:38:53,053 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-13 08:38:53,115 - _trace.py:47 - DEBUG - connect_tcp.started host='raw.githubusercontent.com' port=443 local_address=None timeout=5 socket_options=None
2025-12-13 08:38:53,152 - _trace.py:47 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x14cd7f560>
2025-12-13 08:38:53,152 - _trace.py:47 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x14e648bd0> server_hostname='raw.githubusercontent.com' timeout=5
2025-12-13 08:38:53,190 - _trace.py:47 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x14e3b7e60>
2025-12-13 08:38:53,190 - _trace.py:47 - DEBUG - send_request_headers.started request=<Request [b'GET']>
2025-12-13 08:38:53,190 - _trace.py:47 - DEBUG - send_request_headers.complete
2025-12-13 08:38:53,190 - _trace.py:47 - DEBUG - send_request_body.started request=<Request [b'GET']>
2025-12-13 08:38:53,190 - _trace.py:47 - DEBUG - send_request_body.complete
2025-12-13 08:38:53,190 - _trace.py:47 - DEBUG - receive_response_headers.started request=<Request [b'GET']>
2025-12-13 08:38:53,225 - _trace.py:47 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Connection', b'keep-alive'), (b'Content-Length', b'55842'), (b'Cache-Control', b'max-age=300'), (b'Content-Security-Policy', b"default-src 'none'; style-src 'unsafe-inline'; sandbox"), (b'Content-Type', b'text/plain; charset=utf-8'), (b'ETag', b'W/"3e61c1d6e72c1b8eb8c9c5a8001a6cd74f187355ba209bc10078eac083452c3f"'), (b'Strict-Transport-Security', b'max-age=31536000'), (b'X-Content-Type-Options', b'nosniff'), (b'X-Frame-Options', b'deny'), (b'X-XSS-Protection', b'1; mode=block'), (b'X-GitHub-Request-Id', b'48BD:AA3DE:EAF52:1BA624:693C81AA'), (b'Content-Encoding', b'gzip'), (b'Accept-Ranges', b'bytes'), (b'Date', b'Sat, 13 Dec 2025 11:38:53 GMT'), (b'Via', b'1.1 varnish'), (b'X-Served-By', b'cache-gru-sbsp2090062-GRU'), (b'X-Cache', b'HIT'), (b'X-Cache-Hits', b'22519'), (b'X-Timer', b'S1765625933.223111,VS0,VE0'), (b'Vary', b'Authorization,Accept-Encoding'), (b'Access-Control-Allow-Origin', b'*'), (b'Cross-Origin-Resource-Policy', b'cross-origin'), (b'X-Fastly-Request-ID', b'79fbd873a212b622a48b93df4be37ff3c06d5182'), (b'Expires', b'Sat, 13 Dec 2025 11:43:53 GMT'), (b'Source-Age', b'290')])
2025-12-13 08:38:53,226 - _trace.py:47 - DEBUG - receive_response_body.started request=<Request [b'GET']>
2025-12-13 08:38:53,259 - _trace.py:47 - DEBUG - receive_response_body.complete
2025-12-13 08:38:53,259 - _trace.py:47 - DEBUG - response_closed.started
2025-12-13 08:38:53,259 - _trace.py:47 - DEBUG - response_closed.complete
2025-12-13 08:38:53,260 - _trace.py:47 - DEBUG - close.started
2025-12-13 08:38:53,260 - _trace.py:47 - DEBUG - close.complete
2025-12-13 08:38:53,948 - litellm_logging.py:179 - DEBUG - [Non-Blocking] Unable to import GenericAPILogger - LiteLLM Enterprise Feature - No module named 'litellm_enterprise'
2025-12-13 08:38:54,136 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-13 08:38:54,136 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-13 08:38:54,146 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-13 08:38:54,146 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-13 08:38:54,154 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-13 08:38:54,154 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-13 08:38:54,618 - plugin_manager.py:96 - INFO - Plugin 'logging_plugin' registered.
2025-12-13 08:38:54,619 - plugin_manager.py:96 - INFO - Plugin 'rubric_guardrail' registered.
2025-12-13 08:38:54,619 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-13 08:53:37,026 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-13 08:53:37,027 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-13 08:53:37,088 - _trace.py:47 - DEBUG - connect_tcp.started host='raw.githubusercontent.com' port=443 local_address=None timeout=5 socket_options=None
2025-12-13 08:53:37,124 - _trace.py:47 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x15b6c5370>
2025-12-13 08:53:37,124 - _trace.py:47 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x15f94cbd0> server_hostname='raw.githubusercontent.com' timeout=5
2025-12-13 08:53:37,163 - _trace.py:47 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x15f83a930>
2025-12-13 08:53:37,163 - _trace.py:47 - DEBUG - send_request_headers.started request=<Request [b'GET']>
2025-12-13 08:53:37,163 - _trace.py:47 - DEBUG - send_request_headers.complete
2025-12-13 08:53:37,163 - _trace.py:47 - DEBUG - send_request_body.started request=<Request [b'GET']>
2025-12-13 08:53:37,163 - _trace.py:47 - DEBUG - send_request_body.complete
2025-12-13 08:53:37,163 - _trace.py:47 - DEBUG - receive_response_headers.started request=<Request [b'GET']>
2025-12-13 08:53:37,196 - _trace.py:47 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Connection', b'keep-alive'), (b'Content-Length', b'55842'), (b'Cache-Control', b'max-age=300'), (b'Content-Security-Policy', b"default-src 'none'; style-src 'unsafe-inline'; sandbox"), (b'Content-Type', b'text/plain; charset=utf-8'), (b'ETag', b'W/"3e61c1d6e72c1b8eb8c9c5a8001a6cd74f187355ba209bc10078eac083452c3f"'), (b'Strict-Transport-Security', b'max-age=31536000'), (b'X-Content-Type-Options', b'nosniff'), (b'X-Frame-Options', b'deny'), (b'X-XSS-Protection', b'1; mode=block'), (b'X-GitHub-Request-Id', b'48BD:AA3DE:EAF52:1BA624:693C81AA'), (b'Content-Encoding', b'gzip'), (b'Accept-Ranges', b'bytes'), (b'Date', b'Sat, 13 Dec 2025 11:53:37 GMT'), (b'Via', b'1.1 varnish'), (b'X-Served-By', b'cache-gru-sbsp2090083-GRU'), (b'X-Cache', b'HIT'), (b'X-Cache-Hits', b'8'), (b'X-Timer', b'S1765626817.193603,VS0,VE0'), (b'Vary', b'Authorization,Accept-Encoding'), (b'Access-Control-Allow-Origin', b'*'), (b'Cross-Origin-Resource-Policy', b'cross-origin'), (b'X-Fastly-Request-ID', b'a560d012c5c9ad7695c1b6fc97ce0fcf542586c8'), (b'Expires', b'Sat, 13 Dec 2025 11:58:37 GMT'), (b'Source-Age', b'272')])
2025-12-13 08:53:37,196 - _trace.py:47 - DEBUG - receive_response_body.started request=<Request [b'GET']>
2025-12-13 08:53:37,227 - _trace.py:47 - DEBUG - receive_response_body.complete
2025-12-13 08:53:37,227 - _trace.py:47 - DEBUG - response_closed.started
2025-12-13 08:53:37,227 - _trace.py:47 - DEBUG - response_closed.complete
2025-12-13 08:53:37,228 - _trace.py:47 - DEBUG - close.started
2025-12-13 08:53:37,228 - _trace.py:47 - DEBUG - close.complete
2025-12-13 08:53:37,894 - litellm_logging.py:179 - DEBUG - [Non-Blocking] Unable to import GenericAPILogger - LiteLLM Enterprise Feature - No module named 'litellm_enterprise'
2025-12-13 08:53:38,074 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-13 08:53:38,075 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-13 08:53:38,085 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-13 08:53:38,085 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-13 08:53:38,093 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-13 08:53:38,093 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-13 08:53:38,537 - plugin_manager.py:96 - INFO - Plugin 'logging_plugin' registered.
2025-12-13 08:53:38,537 - plugin_manager.py:96 - INFO - Plugin 'rubric_guardrail' registered.
2025-12-13 08:53:38,538 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-13 08:59:22,474 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-13 08:59:22,476 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-13 08:59:22,541 - _trace.py:47 - DEBUG - connect_tcp.started host='raw.githubusercontent.com' port=443 local_address=None timeout=5 socket_options=None
2025-12-13 08:59:22,575 - _trace.py:47 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12986e300>
2025-12-13 08:59:22,575 - _trace.py:47 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x129f48c50> server_hostname='raw.githubusercontent.com' timeout=5
2025-12-13 08:59:22,614 - _trace.py:47 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x129f54ce0>
2025-12-13 08:59:22,614 - _trace.py:47 - DEBUG - send_request_headers.started request=<Request [b'GET']>
2025-12-13 08:59:22,615 - _trace.py:47 - DEBUG - send_request_headers.complete
2025-12-13 08:59:22,615 - _trace.py:47 - DEBUG - send_request_body.started request=<Request [b'GET']>
2025-12-13 08:59:22,615 - _trace.py:47 - DEBUG - send_request_body.complete
2025-12-13 08:59:22,615 - _trace.py:47 - DEBUG - receive_response_headers.started request=<Request [b'GET']>
2025-12-13 08:59:22,652 - _trace.py:47 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Connection', b'keep-alive'), (b'Content-Length', b'55842'), (b'Cache-Control', b'max-age=300'), (b'Content-Security-Policy', b"default-src 'none'; style-src 'unsafe-inline'; sandbox"), (b'Content-Type', b'text/plain; charset=utf-8'), (b'ETag', b'W/"3e61c1d6e72c1b8eb8c9c5a8001a6cd74f187355ba209bc10078eac083452c3f"'), (b'Strict-Transport-Security', b'max-age=31536000'), (b'X-Content-Type-Options', b'nosniff'), (b'X-Frame-Options', b'deny'), (b'X-XSS-Protection', b'1; mode=block'), (b'X-GitHub-Request-Id', b'48BD:AA3DE:EAF52:1BA624:693C81AA'), (b'Content-Encoding', b'gzip'), (b'Accept-Ranges', b'bytes'), (b'Date', b'Sat, 13 Dec 2025 11:59:22 GMT'), (b'Via', b'1.1 varnish'), (b'X-Served-By', b'cache-gru-sbsp2090075-GRU'), (b'X-Cache', b'HIT'), (b'X-Cache-Hits', b'1'), (b'X-Timer', b'S1765627163.645058,VS0,VE1'), (b'Vary', b'Authorization,Accept-Encoding'), (b'Access-Control-Allow-Origin', b'*'), (b'Cross-Origin-Resource-Policy', b'cross-origin'), (b'X-Fastly-Request-ID', b'46339ede433c2c86affa2dcf47c241c802768255'), (b'Expires', b'Sat, 13 Dec 2025 12:04:22 GMT'), (b'Source-Age', b'15')])
2025-12-13 08:59:22,653 - _trace.py:47 - DEBUG - receive_response_body.started request=<Request [b'GET']>
2025-12-13 08:59:22,687 - _trace.py:47 - DEBUG - receive_response_body.complete
2025-12-13 08:59:22,687 - _trace.py:47 - DEBUG - response_closed.started
2025-12-13 08:59:22,687 - _trace.py:47 - DEBUG - response_closed.complete
2025-12-13 08:59:22,687 - _trace.py:47 - DEBUG - close.started
2025-12-13 08:59:22,687 - _trace.py:47 - DEBUG - close.complete
2025-12-13 08:59:23,357 - litellm_logging.py:179 - DEBUG - [Non-Blocking] Unable to import GenericAPILogger - LiteLLM Enterprise Feature - No module named 'litellm_enterprise'
2025-12-13 08:59:23,534 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-13 08:59:23,535 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-13 08:59:23,545 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-13 08:59:23,545 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-13 08:59:23,553 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-13 08:59:23,553 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-13 08:59:23,998 - plugin_manager.py:96 - INFO - Plugin 'logging_plugin' registered.
2025-12-13 08:59:23,998 - plugin_manager.py:96 - INFO - Plugin 'rubric_guardrail' registered.
2025-12-13 08:59:23,999 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-13 18:12:45,888 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-13 18:12:45,889 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-13 18:12:45,931 - _trace.py:47 - DEBUG - connect_tcp.started host='raw.githubusercontent.com' port=443 local_address=None timeout=5 socket_options=None
2025-12-13 18:12:45,997 - _trace.py:47 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x111d93b90>
2025-12-13 18:12:45,997 - _trace.py:47 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x111d7a7d0> server_hostname='raw.githubusercontent.com' timeout=5
2025-12-13 18:12:46,031 - _trace.py:47 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x111d92f90>
2025-12-13 18:12:46,031 - _trace.py:47 - DEBUG - send_request_headers.started request=<Request [b'GET']>
2025-12-13 18:12:46,031 - _trace.py:47 - DEBUG - send_request_headers.complete
2025-12-13 18:12:46,031 - _trace.py:47 - DEBUG - send_request_body.started request=<Request [b'GET']>
2025-12-13 18:12:46,031 - _trace.py:47 - DEBUG - send_request_body.complete
2025-12-13 18:12:46,031 - _trace.py:47 - DEBUG - receive_response_headers.started request=<Request [b'GET']>
2025-12-13 18:12:46,063 - _trace.py:47 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Connection', b'keep-alive'), (b'Content-Length', b'55842'), (b'Cache-Control', b'max-age=300'), (b'Content-Security-Policy', b"default-src 'none'; style-src 'unsafe-inline'; sandbox"), (b'Content-Type', b'text/plain; charset=utf-8'), (b'ETag', b'W/"3e61c1d6e72c1b8eb8c9c5a8001a6cd74f187355ba209bc10078eac083452c3f"'), (b'Strict-Transport-Security', b'max-age=31536000'), (b'X-Content-Type-Options', b'nosniff'), (b'X-Frame-Options', b'deny'), (b'X-XSS-Protection', b'1; mode=block'), (b'X-GitHub-Request-Id', b'48BD:AA3DE:EAF52:1BA624:693C81AA'), (b'Content-Encoding', b'gzip'), (b'Accept-Ranges', b'bytes'), (b'Date', b'Sat, 13 Dec 2025 21:12:46 GMT'), (b'Via', b'1.1 varnish'), (b'X-Served-By', b'cache-gru-sbsp2090037-GRU'), (b'X-Cache', b'HIT'), (b'X-Cache-Hits', b'3'), (b'X-Timer', b'S1765660366.054682,VS0,VE0'), (b'Vary', b'Authorization,Accept-Encoding'), (b'Access-Control-Allow-Origin', b'*'), (b'Cross-Origin-Resource-Policy', b'cross-origin'), (b'X-Fastly-Request-ID', b'17baf1a31c50c5236c9519e81542155961b47173'), (b'Expires', b'Sat, 13 Dec 2025 21:17:46 GMT'), (b'Source-Age', b'151')])
2025-12-13 18:12:46,075 - _trace.py:47 - DEBUG - receive_response_body.started request=<Request [b'GET']>
2025-12-13 18:12:46,090 - _trace.py:47 - DEBUG - receive_response_body.complete
2025-12-13 18:12:46,090 - _trace.py:47 - DEBUG - response_closed.started
2025-12-13 18:12:46,090 - _trace.py:47 - DEBUG - response_closed.complete
2025-12-13 18:12:46,090 - _trace.py:47 - DEBUG - close.started
2025-12-13 18:12:46,090 - _trace.py:47 - DEBUG - close.complete
2025-12-13 18:12:46,530 - litellm_logging.py:179 - DEBUG - [Non-Blocking] Unable to import GenericAPILogger - LiteLLM Enterprise Feature - No module named 'litellm_enterprise'
2025-12-13 18:12:46,664 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-13 18:12:46,664 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-13 18:12:46,670 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-13 18:12:46,670 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-13 18:12:46,675 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-13 18:12:46,675 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-13 18:12:47,056 - plugin_manager.py:96 - INFO - Plugin 'logging_plugin' registered.
2025-12-13 18:12:47,057 - plugin_manager.py:96 - INFO - Plugin 'rubric_guardrail' registered.
2025-12-13 18:12:47,281 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-13 18:12:47,282 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-13 18:12:47,304 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-13 18:12:47,304 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-13 18:12:47,305 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-13 18:12:47,419 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-13 18:12:47,441 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-13 18:17:53,019 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-13 18:17:53,021 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-13 18:17:53,074 - _trace.py:47 - DEBUG - connect_tcp.started host='raw.githubusercontent.com' port=443 local_address=None timeout=5 socket_options=None
2025-12-13 18:17:53,107 - _trace.py:47 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x13609fcb0>
2025-12-13 18:17:53,108 - _trace.py:47 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1360867d0> server_hostname='raw.githubusercontent.com' timeout=5
2025-12-13 18:17:53,147 - _trace.py:47 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x135b86930>
2025-12-13 18:17:53,147 - _trace.py:47 - DEBUG - send_request_headers.started request=<Request [b'GET']>
2025-12-13 18:17:53,148 - _trace.py:47 - DEBUG - send_request_headers.complete
2025-12-13 18:17:53,148 - _trace.py:47 - DEBUG - send_request_body.started request=<Request [b'GET']>
2025-12-13 18:17:53,148 - _trace.py:47 - DEBUG - send_request_body.complete
2025-12-13 18:17:53,148 - _trace.py:47 - DEBUG - receive_response_headers.started request=<Request [b'GET']>
2025-12-13 18:17:53,182 - _trace.py:47 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Connection', b'keep-alive'), (b'Content-Length', b'55842'), (b'Cache-Control', b'max-age=300'), (b'Content-Security-Policy', b"default-src 'none'; style-src 'unsafe-inline'; sandbox"), (b'Content-Type', b'text/plain; charset=utf-8'), (b'ETag', b'W/"3e61c1d6e72c1b8eb8c9c5a8001a6cd74f187355ba209bc10078eac083452c3f"'), (b'Strict-Transport-Security', b'max-age=31536000'), (b'X-Content-Type-Options', b'nosniff'), (b'X-Frame-Options', b'deny'), (b'X-XSS-Protection', b'1; mode=block'), (b'X-GitHub-Request-Id', b'48BD:AA3DE:EAF52:1BA624:693C81AA'), (b'Content-Encoding', b'gzip'), (b'Accept-Ranges', b'bytes'), (b'Date', b'Sat, 13 Dec 2025 21:17:53 GMT'), (b'Via', b'1.1 varnish'), (b'X-Served-By', b'cache-gru-sbsp2090022-GRU'), (b'X-Cache', b'HIT'), (b'X-Cache-Hits', b'4'), (b'X-Timer', b'S1765660673.170558,VS0,VE0'), (b'Vary', b'Authorization,Accept-Encoding'), (b'Access-Control-Allow-Origin', b'*'), (b'Cross-Origin-Resource-Policy', b'cross-origin'), (b'X-Fastly-Request-ID', b'b24cdb0849f2e092766b24aa1ae9dfdf7d68ce74'), (b'Expires', b'Sat, 13 Dec 2025 21:22:53 GMT'), (b'Source-Age', b'157')])
2025-12-13 18:17:53,183 - _trace.py:47 - DEBUG - receive_response_body.started request=<Request [b'GET']>
2025-12-13 18:17:53,219 - _trace.py:47 - DEBUG - receive_response_body.complete
2025-12-13 18:17:53,219 - _trace.py:47 - DEBUG - response_closed.started
2025-12-13 18:17:53,219 - _trace.py:47 - DEBUG - response_closed.complete
2025-12-13 18:17:53,219 - _trace.py:47 - DEBUG - close.started
2025-12-13 18:17:53,219 - _trace.py:47 - DEBUG - close.complete
2025-12-13 18:17:53,695 - litellm_logging.py:179 - DEBUG - [Non-Blocking] Unable to import GenericAPILogger - LiteLLM Enterprise Feature - No module named 'litellm_enterprise'
2025-12-13 18:17:53,845 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-13 18:17:53,846 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-13 18:17:53,852 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-13 18:17:53,852 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-13 18:17:53,857 - http_handler.py:580 - DEBUG - Using AiohttpTransport...
2025-12-13 18:17:53,857 - http_handler.py:637 - DEBUG - Creating AiohttpTransport...
2025-12-13 18:17:54,186 - plugin_manager.py:96 - INFO - Plugin 'logging_plugin' registered.
2025-12-13 18:17:54,186 - plugin_manager.py:96 - INFO - Plugin 'rubric_guardrail' registered.
2025-12-13 18:17:54,218 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-13 18:17:54,219 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-13 18:17:54,219 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-13 18:17:54,223 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-13 18:17:54,223 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-13 18:17:54,223 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-13 18:17:54,343 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-13 18:17:54,344 - selector_events.py:64 - DEBUG - Using selector: KqueueSelector
2025-12-14 08:10:00,009 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components/__pycache__/sidebar.cpython-311.pyc", inode=76407506, flags=10400, id=808930820): is_file, is_inode_meta_mod
2025-12-14 08:10:00,009 - fsevents.py:90 - DEBUG - queue_event FileModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components/__pycache__/sidebar.cpython-311.pyc', dest_path='', event_type='modified', is_directory=False, is_synthetic=False)
2025-12-14 08:10:00,020 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components/__pycache__/chat.cpython-311.pyc", inode=76407507, flags=10400, id=808930847): is_file, is_inode_meta_mod
2025-12-14 08:10:00,020 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components/__pycache__/results.cpython-311.pyc", inode=76407508, flags=10400, id=808930855): is_file, is_inode_meta_mod
2025-12-14 08:10:00,020 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/utils/__pycache__/__init__.cpython-311.pyc", inode=76407509, flags=10400, id=808930863): is_file, is_inode_meta_mod
2025-12-14 08:10:00,020 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/utils/__pycache__/formatters.cpython-311.pyc", inode=76407510, flags=10400, id=808930871): is_file, is_inode_meta_mod
2025-12-14 08:10:00,020 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/services/__pycache__/__init__.cpython-311.pyc", inode=76407511, flags=10400, id=808930879): is_file, is_inode_meta_mod
2025-12-14 08:10:00,021 - fsevents.py:90 - DEBUG - queue_event FileModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components/__pycache__/chat.cpython-311.pyc', dest_path='', event_type='modified', is_directory=False, is_synthetic=False)
2025-12-14 08:10:00,021 - fsevents.py:90 - DEBUG - queue_event FileModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components/__pycache__/results.cpython-311.pyc', dest_path='', event_type='modified', is_directory=False, is_synthetic=False)
2025-12-14 08:10:00,021 - fsevents.py:90 - DEBUG - queue_event FileModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/utils/__pycache__/__init__.cpython-311.pyc', dest_path='', event_type='modified', is_directory=False, is_synthetic=False)
2025-12-14 08:10:00,021 - fsevents.py:90 - DEBUG - queue_event FileModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/utils/__pycache__/formatters.cpython-311.pyc', dest_path='', event_type='modified', is_directory=False, is_synthetic=False)
2025-12-14 08:10:00,021 - fsevents.py:90 - DEBUG - queue_event FileModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/services/__pycache__/__init__.cpython-311.pyc', dest_path='', event_type='modified', is_directory=False, is_synthetic=False)
2025-12-14 08:10:00,033 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/services/__pycache__/grading.cpython-311.pyc", inode=76407512, flags=10400, id=808930887): is_file, is_inode_meta_mod
2025-12-14 08:10:00,033 - fsevents.py:90 - DEBUG - queue_event FileModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/services/__pycache__/grading.cpython-311.pyc', dest_path='', event_type='modified', is_directory=False, is_synthetic=False)
2025-12-14 08:10:00,216 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/services/__pycache__/grading.cpython-311.pyc", inode=76407512, flags=410400, id=808930905): is_cloned, is_file, is_inode_meta_mod
2025-12-14 08:10:00,218 - fsevents.py:90 - DEBUG - queue_event FileModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/services/__pycache__/grading.cpython-311.pyc', dest_path='', event_type='modified', is_directory=False, is_synthetic=False)
2025-12-14 08:10:00,226 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components/__pycache__/chat.cpython-311.pyc", inode=76407507, flags=410400, id=808930923): is_cloned, is_file, is_inode_meta_mod
2025-12-14 08:10:00,226 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/utils/__pycache__/__init__.cpython-311.pyc", inode=76407509, flags=410400, id=808930941): is_cloned, is_file, is_inode_meta_mod
2025-12-14 08:10:00,226 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/utils/__pycache__/formatters.cpython-311.pyc", inode=76407510, flags=410400, id=808930965): is_cloned, is_file, is_inode_meta_mod
2025-12-14 08:10:00,226 - fsevents.py:90 - DEBUG - queue_event FileModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components/__pycache__/chat.cpython-311.pyc', dest_path='', event_type='modified', is_directory=False, is_synthetic=False)
2025-12-14 08:10:00,226 - fsevents.py:90 - DEBUG - queue_event FileModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/utils/__pycache__/__init__.cpython-311.pyc', dest_path='', event_type='modified', is_directory=False, is_synthetic=False)
2025-12-14 08:10:00,227 - fsevents.py:90 - DEBUG - queue_event FileModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/utils/__pycache__/formatters.cpython-311.pyc', dest_path='', event_type='modified', is_directory=False, is_synthetic=False)
2025-12-14 08:10:00,239 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/services/__pycache__/__init__.cpython-311.pyc", inode=76407511, flags=410400, id=808930983): is_cloned, is_file, is_inode_meta_mod
2025-12-14 08:10:00,239 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components/__pycache__/sidebar.cpython-311.pyc", inode=76407506, flags=410400, id=808931001): is_cloned, is_file, is_inode_meta_mod
2025-12-14 08:10:00,239 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/__pycache__/__init__.cpython-311.pyc", inode=76407504, flags=410400, id=808931019): is_cloned, is_file, is_inode_meta_mod
2025-12-14 08:10:00,239 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components/__pycache__/results.cpython-311.pyc", inode=76407508, flags=410400, id=808931037): is_cloned, is_file, is_inode_meta_mod
2025-12-14 08:10:00,239 - fsevents.py:90 - DEBUG - queue_event FileModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/services/__pycache__/__init__.cpython-311.pyc', dest_path='', event_type='modified', is_directory=False, is_synthetic=False)
2025-12-14 08:10:00,240 - fsevents.py:90 - DEBUG - queue_event FileModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components/__pycache__/sidebar.cpython-311.pyc', dest_path='', event_type='modified', is_directory=False, is_synthetic=False)
2025-12-14 08:10:00,240 - fsevents.py:90 - DEBUG - queue_event FileModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/__pycache__/__init__.cpython-311.pyc', dest_path='', event_type='modified', is_directory=False, is_synthetic=False)
2025-12-14 08:10:00,240 - fsevents.py:90 - DEBUG - queue_event FileModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components/__pycache__/results.cpython-311.pyc', dest_path='', event_type='modified', is_directory=False, is_synthetic=False)
2025-12-14 08:10:00,248 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components/__pycache__/__init__.cpython-311.pyc", inode=76407505, flags=410400, id=808931055): is_cloned, is_file, is_inode_meta_mod
2025-12-14 08:10:00,248 - fsevents.py:90 - DEBUG - queue_event FileModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components/__pycache__/__init__.cpython-311.pyc', dest_path='', event_type='modified', is_directory=False, is_synthetic=False)
2025-12-14 08:10:07,968 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components/__pycache__", inode=75535563, flags=20400, id=808932759): is_directory, is_inode_meta_mod
2025-12-14 08:10:07,968 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components/__pycache__", inode=75535563, flags=20400, id=808932759): is_directory, is_inode_meta_mod
2025-12-14 08:10:07,968 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components/__pycache__/chat.cpython-311.pyc", inode=76407507, flags=18000, id=808932768): is_file, is_xattr_mod
2025-12-14 08:10:07,969 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui", inode=74741817, flags=20400, id=808932765): is_directory, is_inode_meta_mod
2025-12-14 08:10:07,969 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components", inode=75469126, flags=20400, id=808932774): is_directory, is_inode_meta_mod
2025-12-14 08:10:07,969 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components/__pycache__/chat.cpython-311.pyc", inode=76407507, flags=18000, id=808932768): is_file, is_xattr_mod
2025-12-14 08:10:07,969 - fsevents.py:90 - DEBUG - queue_event DirModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components/__pycache__', dest_path='', event_type='modified', is_directory=True, is_synthetic=False)
2025-12-14 08:10:07,970 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components", inode=75469126, flags=20400, id=808932774): is_directory, is_inode_meta_mod
2025-12-14 08:10:07,970 - fsevents.py:90 - DEBUG - queue_event FileModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components/__pycache__/chat.cpython-311.pyc', dest_path='', event_type='modified', is_directory=False, is_synthetic=False)
2025-12-14 08:10:07,970 - fsevents.py:90 - DEBUG - queue_event DirModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components/__pycache__', dest_path='', event_type='modified', is_directory=True, is_synthetic=False)
2025-12-14 08:10:07,970 - fsevents.py:90 - DEBUG - queue_event DirModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components', dest_path='', event_type='modified', is_directory=True, is_synthetic=False)
2025-12-14 08:10:07,970 - fsevents.py:90 - DEBUG - queue_event DirModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui', dest_path='', event_type='modified', is_directory=True, is_synthetic=False)
2025-12-14 08:10:07,971 - fsevents.py:90 - DEBUG - queue_event FileModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components/__pycache__/chat.cpython-311.pyc', dest_path='', event_type='modified', is_directory=False, is_synthetic=False)
2025-12-14 08:10:07,971 - fsevents.py:90 - DEBUG - queue_event DirModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components', dest_path='', event_type='modified', is_directory=True, is_synthetic=False)
2025-12-14 08:10:12,080 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui", inode=74741817, flags=20400, id=808933374): is_directory, is_inode_meta_mod
2025-12-14 08:10:12,081 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/utils/__pycache__/__init__.cpython-311.pyc", inode=76407509, flags=18000, id=808933383): is_file, is_xattr_mod
2025-12-14 08:10:12,081 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/services/__pycache__/__init__.cpython-311.pyc", inode=76407511, flags=18000, id=808933389): is_file, is_xattr_mod
2025-12-14 08:10:12,081 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/__pycache__", inode=75535561, flags=20400, id=808933377): is_directory, is_inode_meta_mod
2025-12-14 08:10:12,081 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/utils/__pycache__/__init__.cpython-311.pyc", inode=76407509, flags=18000, id=808933383): is_file, is_xattr_mod
2025-12-14 08:10:12,081 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/__pycache__/__init__.cpython-311.pyc", inode=76407504, flags=18000, id=808933386): is_file, is_xattr_mod
2025-12-14 08:10:12,081 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/services/__pycache__/__init__.cpython-311.pyc", inode=76407511, flags=18000, id=808933389): is_file, is_xattr_mod
2025-12-14 08:10:12,081 - fsevents.py:90 - DEBUG - queue_event FileModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/services/__pycache__/__init__.cpython-311.pyc', dest_path='', event_type='modified', is_directory=False, is_synthetic=False)
2025-12-14 08:10:12,081 - fsevents.py:90 - DEBUG - queue_event FileModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/utils/__pycache__/__init__.cpython-311.pyc', dest_path='', event_type='modified', is_directory=False, is_synthetic=False)
2025-12-14 08:10:12,081 - fsevents.py:90 - DEBUG - queue_event DirModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui', dest_path='', event_type='modified', is_directory=True, is_synthetic=False)
2025-12-14 08:10:12,082 - fsevents.py:90 - DEBUG - queue_event DirModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/__pycache__', dest_path='', event_type='modified', is_directory=True, is_synthetic=False)
2025-12-14 08:10:12,082 - fsevents.py:90 - DEBUG - queue_event FileModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/utils/__pycache__/__init__.cpython-311.pyc', dest_path='', event_type='modified', is_directory=False, is_synthetic=False)
2025-12-14 08:10:12,082 - fsevents.py:90 - DEBUG - queue_event FileModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/__pycache__/__init__.cpython-311.pyc', dest_path='', event_type='modified', is_directory=False, is_synthetic=False)
2025-12-14 08:10:12,082 - fsevents.py:90 - DEBUG - queue_event FileModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/services/__pycache__/__init__.cpython-311.pyc', dest_path='', event_type='modified', is_directory=False, is_synthetic=False)
2025-12-14 08:10:12,095 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/utils/__pycache__/formatters.cpython-311.pyc", inode=76407510, flags=18000, id=808933392): is_file, is_xattr_mod
2025-12-14 08:10:12,095 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components", inode=75469126, flags=20400, id=808933398): is_directory, is_inode_meta_mod
2025-12-14 08:10:12,095 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/utils/__pycache__/formatters.cpython-311.pyc", inode=76407510, flags=18000, id=808933392): is_file, is_xattr_mod
2025-12-14 08:10:12,095 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/utils", inode=75469181, flags=20400, id=808933413): is_directory, is_inode_meta_mod
2025-12-14 08:10:12,095 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components/__pycache__/results.cpython-311.pyc", inode=76407508, flags=18000, id=808933407): is_file, is_xattr_mod
2025-12-14 08:10:12,095 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components", inode=75469126, flags=20400, id=808933398): is_directory, is_inode_meta_mod
2025-12-14 08:10:12,095 - fsevents.py:90 - DEBUG - queue_event FileModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/utils/__pycache__/formatters.cpython-311.pyc', dest_path='', event_type='modified', is_directory=False, is_synthetic=False)
2025-12-14 08:10:12,095 - fsevents.py:90 - DEBUG - queue_event DirModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components', dest_path='', event_type='modified', is_directory=True, is_synthetic=False)
2025-12-14 08:10:12,095 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components/__pycache__/results.cpython-311.pyc", inode=76407508, flags=18000, id=808933407): is_file, is_xattr_mod
2025-12-14 08:10:12,095 - fsevents.py:90 - DEBUG - queue_event DirModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/utils', dest_path='', event_type='modified', is_directory=True, is_synthetic=False)
2025-12-14 08:10:12,095 - fsevents.py:90 - DEBUG - queue_event FileModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components/__pycache__/results.cpython-311.pyc', dest_path='', event_type='modified', is_directory=False, is_synthetic=False)
2025-12-14 08:10:12,095 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/utils", inode=75469181, flags=20400, id=808933413): is_directory, is_inode_meta_mod
2025-12-14 08:10:12,096 - fsevents.py:90 - DEBUG - queue_event FileModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/utils/__pycache__/formatters.cpython-311.pyc', dest_path='', event_type='modified', is_directory=False, is_synthetic=False)
2025-12-14 08:10:12,096 - fsevents.py:90 - DEBUG - queue_event DirModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components', dest_path='', event_type='modified', is_directory=True, is_synthetic=False)
2025-12-14 08:10:12,096 - fsevents.py:90 - DEBUG - queue_event FileModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components/__pycache__/results.cpython-311.pyc', dest_path='', event_type='modified', is_directory=False, is_synthetic=False)
2025-12-14 08:10:12,096 - fsevents.py:90 - DEBUG - queue_event DirModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/utils', dest_path='', event_type='modified', is_directory=True, is_synthetic=False)
2025-12-14 08:10:12,106 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/services/__pycache__/grading.cpython-311.pyc", inode=76407512, flags=18000, id=808933419): is_file, is_xattr_mod
2025-12-14 08:10:12,106 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components/__pycache__", inode=75535563, flags=20400, id=808933416): is_directory, is_inode_meta_mod
2025-12-14 08:10:12,106 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components/__pycache__", inode=75535563, flags=20400, id=808933416): is_directory, is_inode_meta_mod
2025-12-14 08:10:12,107 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/services", inode=75469157, flags=20400, id=808933422): is_directory, is_inode_meta_mod
2025-12-14 08:10:12,107 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components/__pycache__/__init__.cpython-311.pyc", inode=76407505, flags=18000, id=808933434): is_file, is_xattr_mod
2025-12-14 08:10:12,107 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/services/__pycache__/grading.cpython-311.pyc", inode=76407512, flags=18000, id=808933419): is_file, is_xattr_mod
2025-12-14 08:10:12,107 - fsevents.py:90 - DEBUG - queue_event FileModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/services/__pycache__/grading.cpython-311.pyc', dest_path='', event_type='modified', is_directory=False, is_synthetic=False)
2025-12-14 08:10:12,107 - fsevents.py:90 - DEBUG - queue_event DirModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components/__pycache__', dest_path='', event_type='modified', is_directory=True, is_synthetic=False)
2025-12-14 08:10:12,107 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/services", inode=75469157, flags=20400, id=808933422): is_directory, is_inode_meta_mod
2025-12-14 08:10:12,107 - fsevents.py:90 - DEBUG - queue_event DirModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/services', dest_path='', event_type='modified', is_directory=True, is_synthetic=False)
2025-12-14 08:10:12,107 - fsevents.py:90 - DEBUG - queue_event FileModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components/__pycache__/__init__.cpython-311.pyc', dest_path='', event_type='modified', is_directory=False, is_synthetic=False)
2025-12-14 08:10:12,107 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components/__pycache__/__init__.cpython-311.pyc", inode=76407505, flags=18000, id=808933434): is_file, is_xattr_mod
2025-12-14 08:10:12,107 - fsevents.py:90 - DEBUG - queue_event DirModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components/__pycache__', dest_path='', event_type='modified', is_directory=True, is_synthetic=False)
2025-12-14 08:10:12,108 - fsevents.py:90 - DEBUG - queue_event FileModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/services/__pycache__/grading.cpython-311.pyc', dest_path='', event_type='modified', is_directory=False, is_synthetic=False)
2025-12-14 08:10:12,108 - fsevents.py:90 - DEBUG - queue_event DirModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/services', dest_path='', event_type='modified', is_directory=True, is_synthetic=False)
2025-12-14 08:10:12,108 - fsevents.py:90 - DEBUG - queue_event FileModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components/__pycache__/__init__.cpython-311.pyc', dest_path='', event_type='modified', is_directory=False, is_synthetic=False)
2025-12-14 08:10:12,120 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components/__pycache__/sidebar.cpython-311.pyc", inode=76407506, flags=18000, id=808933446): is_file, is_xattr_mod
2025-12-14 08:10:12,120 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components/__pycache__/sidebar.cpython-311.pyc", inode=76407506, flags=18000, id=808933446): is_file, is_xattr_mod
2025-12-14 08:10:12,120 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/utils/__pycache__", inode=75535568, flags=20400, id=808933449): is_directory, is_inode_meta_mod
2025-12-14 08:10:12,121 - fsevents.py:90 - DEBUG - queue_event DirModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/utils/__pycache__', dest_path='', event_type='modified', is_directory=True, is_synthetic=False)
2025-12-14 08:10:12,120 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/services/__pycache__", inode=75535571, flags=20400, id=808933452): is_directory, is_inode_meta_mod
2025-12-14 08:10:12,120 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/utils/__pycache__", inode=75535568, flags=20400, id=808933449): is_directory, is_inode_meta_mod
2025-12-14 08:10:12,121 - fsevents.py:90 - DEBUG - queue_event FileModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components/__pycache__/sidebar.cpython-311.pyc', dest_path='', event_type='modified', is_directory=False, is_synthetic=False)
2025-12-14 08:10:12,121 - fsevents.py:90 - DEBUG - queue_event DirModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/services/__pycache__', dest_path='', event_type='modified', is_directory=True, is_synthetic=False)
2025-12-14 08:10:12,121 - fsevents.py:163 - DEBUG - NativeEvent(path="/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/services/__pycache__", inode=75535571, flags=20400, id=808933452): is_directory, is_inode_meta_mod
2025-12-14 08:10:12,121 - fsevents.py:90 - DEBUG - queue_event FileModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/components/__pycache__/sidebar.cpython-311.pyc', dest_path='', event_type='modified', is_directory=False, is_synthetic=False)
2025-12-14 08:10:12,121 - fsevents.py:90 - DEBUG - queue_event DirModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/utils/__pycache__', dest_path='', event_type='modified', is_directory=True, is_synthetic=False)
2025-12-14 08:10:12,121 - fsevents.py:90 - DEBUG - queue_event DirModifiedEvent(src_path='/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/ui/services/__pycache__', dest_path='', event_type='modified', is_directory=True, is_synthetic=False)
2025-12-15 07:01:58,872 - gemini_client.py:49 - INFO - Using OpenAI model: gpt-5-mini
2025-12-15 07:01:58,881 - gemini_client.py:49 - INFO - Using OpenAI model: gpt-5-mini
2025-12-15 07:01:58,881 - gemini_client.py:49 - INFO - Using OpenAI model: gpt-5-mini
2025-12-15 07:01:58,881 - gemini_client.py:49 - INFO - Using OpenAI model: gpt-5-mini
2025-12-15 07:01:58,882 - gemini_client.py:49 - INFO - Using OpenAI model: gpt-5-mini
2025-12-15 07:01:58,882 - gemini_client.py:49 - INFO - Using OpenAI model: gpt-5-mini
2025-12-15 07:01:58,882 - gemini_client.py:49 - INFO - Using OpenAI model: gpt-5-mini
2025-12-15 07:01:58,882 - gemini_client.py:49 - INFO - Using OpenAI model: gpt-5-mini
2025-12-15 07:01:58,883 - plugin_manager.py:96 - INFO - Plugin 'logging_plugin' registered.
2025-12-15 07:01:58,883 - plugin_manager.py:96 - INFO - Plugin 'rubric_guardrail' registered.
2025-12-15 07:01:58,911 - gemini_client.py:52 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-15 07:01:58,912 - gemini_client.py:52 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-15 07:01:59,047 - gemini_client.py:52 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-15 07:01:59,047 - gemini_client.py:52 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-15 07:01:59,047 - gemini_client.py:52 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-15 07:01:59,048 - gemini_client.py:52 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-15 07:01:59,048 - gemini_client.py:52 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-15 07:01:59,048 - gemini_client.py:52 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-15 07:01:59,048 - gemini_client.py:52 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-15 07:01:59,048 - gemini_client.py:52 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-15 07:01:59,048 - gemini_client.py:52 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-15 07:01:59,052 - gemini_client.py:52 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-15 07:01:59,053 - gemini_client.py:49 - INFO - Using OpenAI model: gpt-4o-mini
2025-12-15 07:07:12,104 - gemini_client.py:49 - INFO - Using OpenAI model: gpt-5-mini
2025-12-15 07:07:12,114 - gemini_client.py:49 - INFO - Using OpenAI model: gpt-5-mini
2025-12-15 07:07:12,114 - gemini_client.py:49 - INFO - Using OpenAI model: gpt-5-mini
2025-12-15 07:07:12,114 - gemini_client.py:49 - INFO - Using OpenAI model: gpt-5-mini
2025-12-15 07:07:12,114 - gemini_client.py:49 - INFO - Using OpenAI model: gpt-5-mini
2025-12-15 07:07:12,115 - gemini_client.py:49 - INFO - Using OpenAI model: gpt-5-mini
2025-12-15 07:07:12,115 - gemini_client.py:49 - INFO - Using OpenAI model: gpt-5-mini
2025-12-15 07:07:12,115 - gemini_client.py:49 - INFO - Using OpenAI model: gpt-5-mini
2025-12-15 07:07:12,116 - plugin_manager.py:96 - INFO - Plugin 'logging_plugin' registered.
2025-12-15 07:07:12,116 - plugin_manager.py:96 - INFO - Plugin 'rubric_guardrail' registered.
2025-12-15 07:07:12,143 - gemini_client.py:52 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-15 07:07:12,144 - gemini_client.py:52 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-15 07:07:12,146 - gemini_client.py:52 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-15 07:07:12,146 - gemini_client.py:52 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-15 07:07:12,146 - gemini_client.py:52 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-15 07:07:12,147 - gemini_client.py:52 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-15 07:07:12,147 - gemini_client.py:52 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-15 07:07:12,147 - gemini_client.py:52 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-15 07:07:12,147 - gemini_client.py:52 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-15 07:07:12,147 - gemini_client.py:52 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-15 07:07:12,147 - gemini_client.py:52 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-15 07:07:12,150 - gemini_client.py:52 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-15 07:07:12,150 - gemini_client.py:49 - INFO - Using OpenAI model: gpt-4o-mini
2025-12-15 07:25:00,416 - gemini_client.py:49 - INFO - Using OpenAI model: gpt-5-mini
2025-12-15 07:25:00,427 - gemini_client.py:49 - INFO - Using OpenAI model: gpt-5-mini
2025-12-15 07:25:00,427 - gemini_client.py:49 - INFO - Using OpenAI model: gpt-5-mini
2025-12-15 07:25:00,427 - gemini_client.py:49 - INFO - Using OpenAI model: gpt-5-mini
2025-12-15 07:25:00,428 - gemini_client.py:49 - INFO - Using OpenAI model: gpt-5-mini
2025-12-15 07:25:00,428 - gemini_client.py:49 - INFO - Using OpenAI model: gpt-5-mini
2025-12-15 07:25:00,428 - gemini_client.py:49 - INFO - Using OpenAI model: gpt-5-mini
2025-12-15 07:25:00,428 - gemini_client.py:49 - INFO - Using OpenAI model: gpt-5-mini
2025-12-15 07:25:00,430 - plugin_manager.py:96 - INFO - Plugin 'logging_plugin' registered.
2025-12-15 07:25:00,430 - plugin_manager.py:96 - INFO - Plugin 'rubric_guardrail' registered.
2025-12-15 07:25:00,455 - gemini_client.py:52 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-15 07:25:00,456 - gemini_client.py:52 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-15 07:25:00,459 - gemini_client.py:52 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-15 07:25:00,459 - gemini_client.py:52 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-15 07:25:00,459 - gemini_client.py:52 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-15 07:25:00,460 - gemini_client.py:52 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-15 07:25:00,460 - gemini_client.py:52 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-15 07:25:00,460 - gemini_client.py:52 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-15 07:25:00,460 - gemini_client.py:52 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-15 07:25:00,460 - gemini_client.py:52 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-15 07:25:00,460 - gemini_client.py:52 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-15 07:25:00,463 - gemini_client.py:52 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-15 07:25:00,463 - gemini_client.py:49 - INFO - Using OpenAI model: gpt-4o-mini
2025-12-15 12:17:00,861 - gemini_client.py:51 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-15 12:17:00,871 - gemini_client.py:51 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-15 12:17:00,872 - gemini_client.py:51 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-15 12:17:00,872 - gemini_client.py:51 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-15 12:17:00,872 - gemini_client.py:51 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-15 12:17:00,873 - gemini_client.py:51 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-15 12:17:00,993 - gemini_client.py:51 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-15 12:17:01,021 - gemini_client.py:51 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-15 12:17:01,023 - plugin_manager.py:104 - INFO - Plugin 'logging_plugin' registered.
2025-12-15 12:17:01,024 - plugin_manager.py:104 - INFO - Plugin 'rubric_guardrail' registered.
2025-12-15 12:17:01,024 - gemini_client.py:51 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-15 18:17:19,010 - gemini_client.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-15 18:17:19,020 - gemini_client.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-15 18:17:19,021 - gemini_client.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-15 18:17:19,021 - gemini_client.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-15 18:17:19,021 - gemini_client.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-15 18:17:19,021 - gemini_client.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-15 18:17:19,024 - gemini_client.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-15 18:17:19,025 - gemini_client.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-15 18:17:19,026 - plugin_manager.py:96 - INFO - Plugin 'logging_plugin' registered.
2025-12-15 18:17:19,026 - plugin_manager.py:96 - INFO - Plugin 'rubric_guardrail' registered.
2025-12-15 18:17:19,061 - gemini_client.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-15 18:17:19,063 - gemini_client.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-15 18:17:19,066 - gemini_client.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-15 18:17:19,066 - gemini_client.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-15 18:17:19,066 - gemini_client.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-15 18:17:19,067 - gemini_client.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-15 18:17:19,067 - gemini_client.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-15 18:17:19,067 - gemini_client.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-15 18:17:19,067 - gemini_client.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-15 18:17:19,067 - gemini_client.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-15 18:17:19,067 - gemini_client.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-15 18:17:19,071 - gemini_client.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-15 18:17:19,071 - gemini_client.py:57 - INFO - Using OpenAI model: gpt-4o-mini
2025-12-15 18:39:23,166 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-15 18:39:23,175 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-15 18:39:23,175 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-15 18:39:23,175 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-15 18:39:23,186 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-15 18:39:23,187 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-15 18:39:23,189 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-15 18:39:23,190 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-15 18:39:23,191 - plugin_manager.py:96 - INFO - Plugin 'logging_plugin' registered.
2025-12-15 18:39:23,191 - plugin_manager.py:96 - INFO - Plugin 'rubric_guardrail' registered.
2025-12-15 18:39:23,226 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-15 18:39:23,229 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-15 18:39:23,232 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-15 18:39:23,232 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-15 18:39:23,232 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-15 18:39:23,232 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-15 18:39:23,233 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-15 18:39:23,233 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-15 18:39:23,233 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-15 18:39:23,233 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-15 18:39:23,233 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-15 18:39:23,236 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-15 18:39:23,236 - llm_provider.py:57 - INFO - Using OpenAI model: gpt-4o-mini
2025-12-15 18:40:27,063 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-15 18:40:27,071 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-15 18:40:27,071 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-15 18:40:27,071 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-15 18:40:27,071 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-15 18:40:27,071 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-15 18:40:27,073 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-15 18:40:27,074 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-15 18:40:27,074 - plugin_manager.py:96 - INFO - Plugin 'logging_plugin' registered.
2025-12-15 18:40:27,074 - plugin_manager.py:96 - INFO - Plugin 'rubric_guardrail' registered.
2025-12-15 18:40:27,095 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-15 18:40:27,097 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-15 18:40:27,100 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-15 18:40:27,100 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-15 18:40:27,100 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-15 18:40:27,101 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-15 18:40:27,101 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-15 18:40:27,101 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-15 18:40:27,101 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-15 18:40:27,101 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-15 18:40:27,101 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-15 18:40:27,104 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-15 18:40:27,104 - llm_provider.py:57 - INFO - Using OpenAI model: gpt-4o-mini
2025-12-15 18:42:32,254 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-15 18:42:32,267 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-15 18:42:32,267 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-15 18:42:32,267 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-15 18:42:32,268 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-15 18:42:32,268 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-15 18:42:32,270 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-15 18:42:32,271 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-15 18:42:32,272 - plugin_manager.py:96 - INFO - Plugin 'logging_plugin' registered.
2025-12-15 18:42:32,272 - plugin_manager.py:96 - INFO - Plugin 'rubric_guardrail' registered.
2025-12-16 14:36:48,776 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-16 14:36:48,787 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-16 14:36:48,787 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-16 14:36:48,787 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-16 14:36:48,790 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-16 14:36:48,790 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-16 14:36:48,793 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-16 14:36:48,794 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-16 14:36:48,795 - plugin_manager.py:96 - INFO - Plugin 'logging_plugin' registered.
2025-12-16 14:36:48,795 - plugin_manager.py:96 - INFO - Plugin 'rubric_guardrail' registered.
2025-12-16 16:44:24,644 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-16 16:44:24,657 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-16 16:44:24,658 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-16 16:44:24,658 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-16 16:44:24,658 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-16 16:44:24,659 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-16 16:44:24,661 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-16 16:44:24,662 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-16 16:44:24,664 - plugin_manager.py:96 - INFO - Plugin 'logging_plugin' registered.
2025-12-16 16:44:24,664 - plugin_manager.py:96 - INFO - Plugin 'rubric_guardrail' registered.
2025-12-16 16:45:23,743 - utils.py:3347 - INFO - 
LiteLLM completion() model= responses/gpt-5-mini; provider = openai
2025-12-16 16:47:54,192 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-16 16:47:54,219 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-16 16:47:54,219 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-16 16:47:54,220 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-16 16:47:54,220 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-16 16:47:54,221 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-16 16:47:54,224 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-16 16:47:54,224 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-16 16:47:54,226 - plugin_manager.py:96 - INFO - Plugin 'logging_plugin' registered.
2025-12-16 16:47:54,226 - plugin_manager.py:96 - INFO - Plugin 'rubric_guardrail' registered.
2025-12-16 16:49:09,021 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 16:50:15,459 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-16 16:50:15,472 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-16 16:50:15,473 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-16 16:50:15,473 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-16 16:50:15,473 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-16 16:50:15,474 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-16 16:50:15,476 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-16 16:50:15,476 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-16 16:50:15,478 - plugin_manager.py:96 - INFO - Plugin 'logging_plugin' registered.
2025-12-16 16:50:15,478 - plugin_manager.py:96 - INFO - Plugin 'rubric_guardrail' registered.
2025-12-16 16:50:48,295 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 16:50:50,182 - google_llm.py:186 - INFO - Response received from the model.
2025-12-16 16:50:50,183 - types.py:6324 - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2025-12-16 16:50:50,184 - plugin_manager.py:96 - INFO - Plugin 'logging_plugin' registered.
2025-12-16 16:50:50,184 - plugin_manager.py:96 - INFO - Plugin 'rubric_guardrail' registered.
2025-12-16 16:50:50,211 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 16:50:52,027 - google_llm.py:186 - INFO - Response received from the model.
2025-12-16 16:50:52,027 - types.py:6324 - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2025-12-16 16:50:52,029 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 16:50:52,901 - google_llm.py:186 - INFO - Response received from the model.
2025-12-16 16:50:52,903 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 16:50:53,495 - google_llm.py:186 - INFO - Response received from the model.
2025-12-16 16:50:53,496 - runners.py:432 - INFO - Running event compactor.
2025-12-16 16:50:53,498 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 16:50:54,399 - google_llm.py:186 - INFO - Response received from the model.
2025-12-16 16:50:54,399 - types.py:6324 - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2025-12-16 16:50:54,401 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 16:50:54,918 - google_llm.py:186 - INFO - Response received from the model.
2025-12-16 16:50:54,920 - runners.py:432 - INFO - Running event compactor.
2025-12-16 16:53:46,979 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-16 16:53:46,991 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-16 16:53:46,991 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-16 16:53:46,991 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-16 16:53:46,991 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-16 16:53:46,992 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-16 16:53:46,994 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-16 16:53:46,995 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-16 16:53:46,996 - plugin_manager.py:96 - INFO - Plugin 'logging_plugin' registered.
2025-12-16 16:53:46,996 - plugin_manager.py:96 - INFO - Plugin 'rubric_guardrail' registered.
2025-12-16 16:54:09,400 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 16:54:12,267 - google_llm.py:186 - INFO - Response received from the model.
2025-12-16 16:54:12,267 - types.py:6324 - WARNING - Warning: there are non-text parts in the response: ['function_call', 'thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2025-12-16 16:54:12,269 - plugin_manager.py:96 - INFO - Plugin 'logging_plugin' registered.
2025-12-16 16:54:12,269 - plugin_manager.py:96 - INFO - Plugin 'rubric_guardrail' registered.
2025-12-16 16:54:12,307 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 16:54:14,892 - google_llm.py:186 - INFO - Response received from the model.
2025-12-16 16:54:14,892 - types.py:6324 - WARNING - Warning: there are non-text parts in the response: ['function_call', 'thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2025-12-16 16:54:14,894 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 16:54:16,935 - google_llm.py:186 - INFO - Response received from the model.
2025-12-16 16:54:16,935 - types.py:6324 - WARNING - Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2025-12-16 16:54:16,938 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 16:54:19,187 - google_llm.py:186 - INFO - Response received from the model.
2025-12-16 16:54:19,188 - types.py:6324 - WARNING - Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2025-12-16 16:54:19,188 - runners.py:432 - INFO - Running event compactor.
2025-12-16 16:54:19,190 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 16:54:20,793 - google_llm.py:186 - INFO - Response received from the model.
2025-12-16 16:54:20,793 - types.py:6324 - WARNING - Warning: there are non-text parts in the response: ['function_call', 'thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2025-12-16 16:54:20,796 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 16:54:21,746 - google_llm.py:186 - INFO - Response received from the model.
2025-12-16 16:54:21,746 - types.py:6324 - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2025-12-16 16:54:21,748 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-16 16:54:21,748 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-16 16:54:21,748 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-16 16:54:21,774 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 16:54:21,774 - models.py:6856 - INFO - AFC is enabled with max remote calls: 10.
2025-12-16 16:54:21,805 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 16:54:21,805 - models.py:6856 - INFO - AFC is enabled with max remote calls: 10.
2025-12-16 16:54:22,262 - before_sleep.py:65 - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 1.1512171219062144 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 37.905960711s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '37s'}]}}.
2025-12-16 16:54:22,894 - before_sleep.py:65 - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 1.372839660080503 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 37.240353667s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '37s'}]}}.
2025-12-16 16:54:24,604 - before_sleep.py:65 - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 7.056147093543181 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 35.582891202s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '35s'}]}}.
2025-12-16 16:54:28,502 - google_llm.py:186 - INFO - Response received from the model.
2025-12-16 16:54:28,530 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 16:54:28,531 - models.py:6856 - INFO - AFC is enabled with max remote calls: 10.
2025-12-16 16:54:28,937 - before_sleep.py:65 - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 1.16057631940486 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 31.196469015s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '31s'}]}}.
2025-12-16 16:54:30,382 - before_sleep.py:65 - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 7.443618598121408 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 29.752844577s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '29s'}]}}.
2025-12-16 16:54:32,398 - before_sleep.py:65 - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 49.652242439684315 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 27.822201056s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '27s'}]}}.
2025-12-16 16:54:38,136 - before_sleep.py:65 - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 49.46629557780415 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 22.020605782s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '22s'}]}}.
2025-12-16 16:55:26,677 - google_llm.py:186 - INFO - Response received from the model.
2025-12-16 16:55:30,711 - google_llm.py:186 - INFO - Response received from the model.
2025-12-16 16:55:30,746 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 16:55:33,408 - google_llm.py:186 - INFO - Response received from the model.
2025-12-16 16:55:33,408 - types.py:6324 - WARNING - Warning: there are non-text parts in the response: ['function_call', 'thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2025-12-16 16:55:33,411 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 16:55:36,502 - google_llm.py:186 - INFO - Response received from the model.
2025-12-16 16:55:36,502 - types.py:6324 - WARNING - Warning: there are non-text parts in the response: ['function_call', 'thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2025-12-16 16:55:36,536 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 16:55:40,230 - google_llm.py:186 - INFO - Response received from the model.
2025-12-16 16:55:40,231 - types.py:6324 - WARNING - Warning: there are non-text parts in the response: ['function_call', 'thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2025-12-16 16:55:40,285 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 16:55:40,285 - models.py:6856 - INFO - AFC is enabled with max remote calls: 10.
2025-12-16 16:55:52,070 - google_llm.py:186 - INFO - Response received from the model.
2025-12-16 16:55:52,072 - runners.py:432 - INFO - Running event compactor.
2025-12-16 16:59:01,279 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 16:59:18,271 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 16:59:57,570 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 17:00:14,437 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-16 17:00:14,450 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-16 17:00:14,451 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-16 17:00:14,451 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-16 17:00:14,451 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-16 17:00:14,451 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-16 17:00:14,454 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-16 17:00:14,454 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-16 17:00:14,456 - plugin_manager.py:96 - INFO - Plugin 'logging_plugin' registered.
2025-12-16 17:00:14,456 - plugin_manager.py:96 - INFO - Plugin 'rubric_guardrail' registered.
2025-12-16 17:00:31,006 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 17:00:32,751 - before_sleep.py:65 - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 1.216217501236898 seconds as it raised ServerError: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}.
2025-12-16 17:00:36,791 - google_llm.py:186 - INFO - Response received from the model.
2025-12-16 17:00:36,791 - types.py:6324 - WARNING - Warning: there are non-text parts in the response: ['function_call', 'thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2025-12-16 17:00:36,794 - plugin_manager.py:96 - INFO - Plugin 'logging_plugin' registered.
2025-12-16 17:00:36,794 - plugin_manager.py:96 - INFO - Plugin 'rubric_guardrail' registered.
2025-12-16 17:00:36,831 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 17:00:40,302 - google_llm.py:186 - INFO - Response received from the model.
2025-12-16 17:00:40,302 - types.py:6324 - WARNING - Warning: there are non-text parts in the response: ['function_call', 'thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2025-12-16 17:00:40,304 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 17:00:41,818 - google_llm.py:186 - INFO - Response received from the model.
2025-12-16 17:00:41,820 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 17:00:43,301 - google_llm.py:186 - INFO - Response received from the model.
2025-12-16 17:00:43,301 - types.py:6324 - WARNING - Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2025-12-16 17:00:43,302 - runners.py:432 - INFO - Running event compactor.
2025-12-16 17:00:43,303 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 17:00:45,944 - google_llm.py:186 - INFO - Response received from the model.
2025-12-16 17:00:45,944 - types.py:6324 - WARNING - Warning: there are non-text parts in the response: ['function_call', 'thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2025-12-16 17:00:45,946 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 17:00:47,542 - google_llm.py:186 - INFO - Response received from the model.
2025-12-16 17:00:47,542 - types.py:6324 - WARNING - Warning: there are non-text parts in the response: ['function_call', 'thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2025-12-16 17:00:47,543 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-16 17:00:47,544 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-16 17:00:47,544 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-16 17:00:47,544 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash
2025-12-16 17:00:47,571 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 17:00:47,571 - models.py:6856 - INFO - AFC is enabled with max remote calls: 10.
2025-12-16 17:00:47,603 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 17:00:47,603 - models.py:6856 - INFO - AFC is enabled with max remote calls: 10.
2025-12-16 17:00:48,038 - before_sleep.py:65 - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 1.8684986237043901 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 12.103206363s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '12s'}]}}.
2025-12-16 17:00:48,729 - before_sleep.py:65 - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 1.5599842786304716 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 11.431671321s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '11s'}]}}.
2025-12-16 17:00:50,200 - before_sleep.py:65 - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 7.32469368349374 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 9.93979194s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '9s'}]}}.
2025-12-16 17:00:50,631 - before_sleep.py:65 - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 7.650312389755776 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 9.506052285s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '9s'}]}}.
2025-12-16 17:00:57,839 - before_sleep.py:65 - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 49.61109064532019 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 2.317391917s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '2s'}]}}.
2025-12-16 17:00:58,570 - before_sleep.py:65 - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 49.156054946677806 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 1.567678543s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '1s'}]}}.
2025-12-16 17:01:48,145 - before_sleep.py:65 - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 60.0 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 11.993381555s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '11s'}]}}.
2025-12-16 17:01:52,482 - google_llm.py:186 - INFO - Response received from the model.
2025-12-16 17:01:52,514 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 17:01:52,515 - models.py:6856 - INFO - AFC is enabled with max remote calls: 10.
2025-12-16 17:01:52,938 - before_sleep.py:65 - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 1.048860435791779 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 7.207891662s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '7s'}]}}.
2025-12-16 17:01:54,276 - before_sleep.py:65 - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 7.088405552409983 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 5.861814179s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '5s'}]}}.
2025-12-16 17:02:01,688 - before_sleep.py:65 - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 49.62237008032363 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 58.487378465s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '58s'}]}}.
2025-12-16 17:02:48,665 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 17:02:48,666 - models.py:6856 - INFO - AFC is enabled with max remote calls: 10.
2025-12-16 17:02:48,676 - base_events.py:1819 - ERROR - Task <Task finished name='Task-249' coro=<_merge_agent_run.<locals>.process_an_agent() done, defined at /Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/adk/agents/parallel_agent.py:134> exception=ClientError("429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 11.536805581s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '11s'}]}}")> has errored out but its parent task <Task finished name='Task-247' coro=<<async_generator_asend without __name__>()> result={'data': {'criterion_name': 'Thesis and Argumentation', 'evaluation_notes': 'The thesis i...m throughout.', 'max_score': 35, 'score': 32.0}, 'step': 'grading', 'type': 'criterion_graded'}> is already completed
task: <Task finished name='Task-249' coro=<_merge_agent_run.<locals>.process_an_agent() done, defined at /Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/adk/agents/parallel_agent.py:134> exception=ClientError("429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 11.536805581s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '11s'}]}}")>
Traceback (most recent call last):
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/adk/agents/parallel_agent.py", line 136, in process_an_agent
    async for event in events_for_one_agent:
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/adk/agents/base_agent.py", line 294, in run_async
    async for event in agen:
  File "/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/agents/graders.py", line 56, in _run_async_impl
    async for event in agen:
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/adk/agents/base_agent.py", line 294, in run_async
    async for event in agen:
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/adk/agents/llm_agent.py", line 435, in _run_async_impl
    async for event in agen:
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 356, in run_async
    async for event in agen:
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 433, in _run_one_step_async
    async for llm_response in agen:
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 804, in _call_llm_async
    async for event in agen:
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 788, in _call_llm_with_tracing
    async for llm_response in agen:
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 998, in _run_and_handle_error
    raise model_error
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 982, in _run_and_handle_error
    async for response in agen:
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/adk/models/google_llm.py", line 181, in generate_content_async
    response = await self.api_client.aio.models.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/genai/models.py", line 6862, in generate_content
    response = await self._generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/genai/models.py", line 5673, in _generate_content
    response = await self._api_client.async_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/genai/_api_client.py", line 1365, in async_request
    result = await self._async_request(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/genai/_api_client.py", line 1310, in _async_request
    return await self._async_retry(  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/tenacity/asyncio/__init__.py", line 111, in __call__
    do = await self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/tenacity/__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/tenacity/__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rafaelventura/miniconda3/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/rafaelventura/miniconda3/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/tenacity/asyncio/__init__.py", line 114, in __call__
    result = await fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/genai/_api_client.py", line 1255, in _async_request_once
    await errors.APIError.raise_for_async_response(response)
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/genai/errors.py", line 166, in raise_for_async_response
    raise ClientError(status_code, response_json, response)
google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 11.536805581s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '11s'}]}}
2025-12-16 17:02:49,141 - before_sleep.py:65 - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 1.7982529054564984 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 11.036333119s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '11s'}]}}.
2025-12-16 17:02:51,290 - before_sleep.py:65 - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 7.3588528506327116 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.893408933s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}.
2025-12-16 17:02:51,805 - before_sleep.py:65 - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 60.0 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.414836986s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}.
2025-12-16 17:02:58,942 - before_sleep.py:65 - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 49.820855614919076 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 1.186834658s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '1s'}]}}.
2025-12-16 17:03:49,201 - before_sleep.py:65 - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 60.0 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 10.933131414s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}.
2025-12-16 17:03:52,904 - base_events.py:1819 - ERROR - Task <Task finished name='Task-250' coro=<_merge_agent_run.<locals>.process_an_agent() done, defined at /Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/adk/agents/parallel_agent.py:134> exception=ClientError("429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 7.224605251s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '7s'}]}}")> has errored out but its parent task <Task finished name='Task-247' coro=<<async_generator_asend without __name__>()> result={'data': {'criterion_name': 'Thesis and Argumentation', 'evaluation_notes': 'The thesis i...m throughout.', 'max_score': 35, 'score': 32.0}, 'step': 'grading', 'type': 'criterion_graded'}> is already completed
task: <Task finished name='Task-250' coro=<_merge_agent_run.<locals>.process_an_agent() done, defined at /Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/adk/agents/parallel_agent.py:134> exception=ClientError("429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 7.224605251s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '7s'}]}}")>
Traceback (most recent call last):
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/adk/agents/parallel_agent.py", line 136, in process_an_agent
    async for event in events_for_one_agent:
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/adk/agents/base_agent.py", line 294, in run_async
    async for event in agen:
  File "/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/agents/graders.py", line 56, in _run_async_impl
    async for event in agen:
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/adk/agents/base_agent.py", line 294, in run_async
    async for event in agen:
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/adk/agents/llm_agent.py", line 435, in _run_async_impl
    async for event in agen:
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 356, in run_async
    async for event in agen:
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 433, in _run_one_step_async
    async for llm_response in agen:
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 804, in _call_llm_async
    async for event in agen:
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 788, in _call_llm_with_tracing
    async for llm_response in agen:
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 998, in _run_and_handle_error
    raise model_error
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 982, in _run_and_handle_error
    async for response in agen:
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/adk/models/google_llm.py", line 181, in generate_content_async
    response = await self.api_client.aio.models.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/genai/models.py", line 6862, in generate_content
    response = await self._generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/genai/models.py", line 5673, in _generate_content
    response = await self._api_client.async_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/genai/_api_client.py", line 1365, in async_request
    result = await self._async_request(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/genai/_api_client.py", line 1310, in _async_request
    return await self._async_retry(  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/tenacity/asyncio/__init__.py", line 111, in __call__
    do = await self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/tenacity/__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/tenacity/__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rafaelventura/miniconda3/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/rafaelventura/miniconda3/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/tenacity/asyncio/__init__.py", line 114, in __call__
    result = await fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/genai/_api_client.py", line 1255, in _async_request_once
    await errors.APIError.raise_for_async_response(response)
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/genai/errors.py", line 166, in raise_for_async_response
    raise ClientError(status_code, response_json, response)
google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 7.224605251s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '7s'}]}}
2025-12-16 17:04:49,669 - base_events.py:1819 - ERROR - Task <Task finished name='Task-251' coro=<_merge_agent_run.<locals>.process_an_agent() done, defined at /Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/adk/agents/parallel_agent.py:134> exception=ClientError("429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 10.496238027s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}")> has errored out but its parent task <Task finished name='Task-247' coro=<<async_generator_asend without __name__>()> result={'data': {'criterion_name': 'Thesis and Argumentation', 'evaluation_notes': 'The thesis i...m throughout.', 'max_score': 35, 'score': 32.0}, 'step': 'grading', 'type': 'criterion_graded'}> is already completed
task: <Task finished name='Task-251' coro=<_merge_agent_run.<locals>.process_an_agent() done, defined at /Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/adk/agents/parallel_agent.py:134> exception=ClientError("429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 10.496238027s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}")>
Traceback (most recent call last):
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/adk/agents/parallel_agent.py", line 136, in process_an_agent
    async for event in events_for_one_agent:
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/adk/agents/base_agent.py", line 294, in run_async
    async for event in agen:
  File "/Users/rafaelventura/Desktop/projects/ai_agents-course-sdk-google/capstone/agents/graders.py", line 56, in _run_async_impl
    async for event in agen:
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/adk/agents/base_agent.py", line 294, in run_async
    async for event in agen:
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/adk/agents/llm_agent.py", line 435, in _run_async_impl
    async for event in agen:
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 356, in run_async
    async for event in agen:
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 433, in _run_one_step_async
    async for llm_response in agen:
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 804, in _call_llm_async
    async for event in agen:
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 788, in _call_llm_with_tracing
    async for llm_response in agen:
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 998, in _run_and_handle_error
    raise model_error
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py", line 982, in _run_and_handle_error
    async for response in agen:
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/adk/models/google_llm.py", line 181, in generate_content_async
    response = await self.api_client.aio.models.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/genai/models.py", line 6862, in generate_content
    response = await self._generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/genai/models.py", line 5673, in _generate_content
    response = await self._api_client.async_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/genai/_api_client.py", line 1365, in async_request
    result = await self._async_request(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/genai/_api_client.py", line 1310, in _async_request
    return await self._async_retry(  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/tenacity/asyncio/__init__.py", line 111, in __call__
    do = await self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/tenacity/__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/tenacity/__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rafaelventura/miniconda3/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/rafaelventura/miniconda3/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/tenacity/asyncio/__init__.py", line 114, in __call__
    result = await fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/genai/_api_client.py", line 1255, in _async_request_once
    await errors.APIError.raise_for_async_response(response)
  File "/Users/rafaelventura/miniconda3/lib/python3.12/site-packages/google/genai/errors.py", line 166, in raise_for_async_response
    raise ClientError(status_code, response_json, response)
google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 10.496238027s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
2025-12-16 17:05:37,261 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-16 17:05:37,273 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-16 17:05:37,273 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-16 17:05:37,273 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-16 17:05:37,274 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-16 17:05:37,274 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-16 17:05:37,277 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-16 17:05:37,277 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-16 17:05:37,278 - plugin_manager.py:96 - INFO - Plugin 'logging_plugin' registered.
2025-12-16 17:05:37,279 - plugin_manager.py:96 - INFO - Plugin 'rubric_guardrail' registered.
2025-12-16 17:05:55,431 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 17:05:57,225 - google_llm.py:186 - INFO - Response received from the model.
2025-12-16 17:05:57,226 - types.py:6324 - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2025-12-16 17:05:57,227 - plugin_manager.py:96 - INFO - Plugin 'logging_plugin' registered.
2025-12-16 17:05:57,228 - plugin_manager.py:96 - INFO - Plugin 'rubric_guardrail' registered.
2025-12-16 17:05:57,255 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 17:05:58,587 - google_llm.py:186 - INFO - Response received from the model.
2025-12-16 17:05:58,587 - types.py:6324 - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2025-12-16 17:05:58,591 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 17:05:59,945 - google_llm.py:186 - INFO - Response received from the model.
2025-12-16 17:05:59,957 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 17:06:01,346 - google_llm.py:186 - INFO - Response received from the model.
2025-12-16 17:06:01,348 - runners.py:432 - INFO - Running event compactor.
2025-12-16 17:06:01,350 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 17:06:02,144 - google_llm.py:186 - INFO - Response received from the model.
2025-12-16 17:06:02,144 - types.py:6324 - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2025-12-16 17:06:02,148 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 17:06:03,224 - google_llm.py:186 - INFO - Response received from the model.
2025-12-16 17:06:03,225 - types.py:6324 - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2025-12-16 17:06:03,227 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-16 17:06:03,227 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-16 17:06:03,227 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-16 17:06:03,228 - llm_provider.py:60 - INFO - Using Gemini model: gemini-2.5-flash-lite
2025-12-16 17:06:03,258 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 17:06:03,259 - models.py:6856 - INFO - AFC is enabled with max remote calls: 10.
2025-12-16 17:06:03,289 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 17:06:03,289 - models.py:6856 - INFO - AFC is enabled with max remote calls: 10.
2025-12-16 17:06:04,684 - google_llm.py:186 - INFO - Response received from the model.
2025-12-16 17:06:04,712 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 17:06:04,712 - models.py:6856 - INFO - AFC is enabled with max remote calls: 10.
2025-12-16 17:06:04,774 - google_llm.py:186 - INFO - Response received from the model.
2025-12-16 17:06:04,800 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 17:06:04,800 - models.py:6856 - INFO - AFC is enabled with max remote calls: 10.
2025-12-16 17:06:06,245 - google_llm.py:186 - INFO - Response received from the model.
2025-12-16 17:06:06,348 - google_llm.py:186 - INFO - Response received from the model.
2025-12-16 17:06:06,379 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 17:06:07,410 - google_llm.py:186 - INFO - Response received from the model.
2025-12-16 17:06:07,410 - types.py:6324 - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2025-12-16 17:06:07,414 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 17:06:12,451 - google_llm.py:186 - INFO - Response received from the model.
2025-12-16 17:06:12,452 - types.py:6324 - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2025-12-16 17:06:12,483 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 17:06:12,919 - before_sleep.py:65 - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 1.578623670511074 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10, model: gemini-2.5-flash-lite\nPlease retry in 47.161845521s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '47s'}]}}.
2025-12-16 17:06:14,866 - before_sleep.py:65 - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 7.603859910879563 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10, model: gemini-2.5-flash-lite\nPlease retry in 45.30174955s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '45s'}]}}.
2025-12-16 17:06:22,851 - before_sleep.py:65 - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 49.417628167148756 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10, model: gemini-2.5-flash-lite\nPlease retry in 37.325073802s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '37s'}]}}.
2025-12-16 17:07:13,850 - google_llm.py:186 - INFO - Response received from the model.
2025-12-16 17:07:13,852 - types.py:6324 - WARNING - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2025-12-16 17:07:13,863 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 17:07:14,510 - google_llm.py:186 - INFO - Response received from the model.
2025-12-16 17:07:14,542 - google_llm.py:133 - INFO - Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-16 17:07:14,542 - models.py:6856 - INFO - AFC is enabled with max remote calls: 10.
2025-12-16 17:07:14,963 - before_sleep.py:65 - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 1.0838903247845195 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\nPlease retry in 45.119197256s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '45s'}]}}.
2025-12-16 17:07:16,411 - before_sleep.py:65 - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 7.2746065224893295 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\nPlease retry in 43.756977006s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '43s'}]}}.
2025-12-16 17:07:23,986 - before_sleep.py:65 - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 49.7597757895176 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\nPlease retry in 36.119300657s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '36s'}]}}.
2025-12-16 17:08:14,262 - before_sleep.py:65 - INFO - Retrying google.genai._api_client.BaseApiClient._async_request_once in 60.0 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\nPlease retry in 45.837968291s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '45s'}]}}.
2025-12-16 17:10:43,761 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-16 17:10:43,775 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-16 17:10:43,775 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-16 17:10:43,775 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-16 17:10:43,775 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-16 17:10:43,776 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-16 17:10:43,779 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-16 17:10:43,779 - llm_provider.py:57 - INFO - Using OpenAI model: openai/responses/gpt-5-mini
2025-12-16 17:10:43,781 - plugin_manager.py:96 - INFO - Plugin 'logging_plugin' registered.
2025-12-16 17:10:43,781 - plugin_manager.py:96 - INFO - Plugin 'rubric_guardrail' registered.
2025-12-16 17:12:16,896 - utils.py:3347 - INFO - 
LiteLLM completion() model= responses/gpt-5-mini; provider = openai
2025-12-16 18:14:55,714 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 18:14:55,730 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 18:14:55,731 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 18:14:55,731 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 18:14:55,732 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 18:14:55,732 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 18:14:55,735 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 18:14:55,736 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 18:14:55,738 - plugin_manager.py:96 - INFO - Plugin 'logging_plugin' registered.
2025-12-16 18:14:55,738 - plugin_manager.py:96 - INFO - Plugin 'rubric_guardrail' registered.
2025-12-16 18:15:16,174 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 18:15:23,066 - plugin_manager.py:96 - INFO - Plugin 'logging_plugin' registered.
2025-12-16 18:15:23,066 - plugin_manager.py:96 - INFO - Plugin 'rubric_guardrail' registered.
2025-12-16 18:15:23,069 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 18:15:29,984 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 18:15:34,056 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 18:15:38,116 - runners.py:432 - INFO - Running event compactor.
2025-12-16 18:15:38,159 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 18:15:44,810 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 18:15:45,800 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 18:15:45,800 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 18:15:45,800 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 18:15:45,805 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 18:15:45,807 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 18:15:56,488 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 18:16:09,574 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 18:16:14,453 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 18:16:19,007 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 18:16:34,643 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 18:16:35,410 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 18:16:49,194 - runners.py:432 - INFO - Running event compactor.
2025-12-16 20:48:22,352 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 20:48:22,359 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 20:48:22,359 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 20:48:22,359 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 20:48:22,359 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 20:48:22,360 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 20:48:22,361 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 20:48:22,362 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 20:48:22,362 - plugin_manager.py:96 - INFO - Plugin 'logging_plugin' registered.
2025-12-16 20:48:22,363 - plugin_manager.py:96 - INFO - Plugin 'rubric_guardrail' registered.
2025-12-16 20:48:45,792 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 20:48:50,499 - plugin_manager.py:96 - INFO - Plugin 'logging_plugin' registered.
2025-12-16 20:48:50,499 - plugin_manager.py:96 - INFO - Plugin 'rubric_guardrail' registered.
2025-12-16 20:48:50,502 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 20:48:55,913 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 20:48:58,273 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 20:49:01,402 - runners.py:432 - INFO - Running event compactor.
2025-12-16 20:49:01,406 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 20:49:05,534 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 20:49:08,446 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 20:49:08,447 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 20:49:08,447 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 20:49:08,452 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 20:49:08,458 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 20:49:16,303 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 20:49:22,944 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 20:49:27,236 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 20:49:31,257 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 20:49:42,606 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 20:49:54,178 - runners.py:432 - INFO - Running event compactor.
2025-12-16 20:50:33,762 - runners.py:902 - WARNING - Event from an unknown agent: FeedbackGeneratorAgent_llm, event id: 6fd45bb8-39bf-45e2-a51e-607fa5a4570f
2025-12-16 20:50:33,764 - runners.py:902 - WARNING - Event from an unknown agent: Grader_documentation_llm, event id: 6982daff-c73d-475e-b831-0c812908afcf
2025-12-16 20:50:33,764 - runners.py:902 - WARNING - Event from an unknown agent: Grader_code_quality_llm, event id: 900ebd41-45ad-4896-96f0-0d264fe9ecc4
2025-12-16 20:50:33,764 - runners.py:902 - WARNING - Event from an unknown agent: Grader_functionality_llm, event id: 5f1bd8b4-f7c0-437f-a5ca-6cce7d0f6fef
2025-12-16 20:50:33,772 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 20:50:42,920 - plugin_manager.py:96 - INFO - Plugin 'logging_plugin' registered.
2025-12-16 20:50:42,921 - plugin_manager.py:96 - INFO - Plugin 'rubric_guardrail' registered.
2025-12-16 20:50:42,926 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 20:50:48,042 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 20:50:50,907 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 20:50:52,754 - runners.py:432 - INFO - Running event compactor.
2025-12-16 20:50:52,765 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 20:50:59,614 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 20:51:01,656 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 20:51:01,657 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 20:51:01,657 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 20:51:01,657 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 20:51:01,669 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 20:51:01,670 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 20:51:06,880 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 20:51:09,648 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 20:51:17,331 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 20:51:21,426 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 20:51:25,563 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 20:51:32,327 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 20:51:33,716 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 20:51:48,660 - runners.py:432 - INFO - Running event compactor.
2025-12-16 21:05:04,735 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 21:05:04,750 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 21:05:04,751 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 21:05:04,751 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 21:05:04,751 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 21:05:04,751 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 21:05:04,753 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 21:05:04,753 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 21:05:04,754 - plugin_manager.py:96 - INFO - Plugin 'logging_plugin' registered.
2025-12-16 21:05:04,754 - plugin_manager.py:96 - INFO - Plugin 'rubric_guardrail' registered.
2025-12-16 21:05:49,551 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 21:05:49,557 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 21:05:49,557 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 21:05:49,557 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 21:05:49,558 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 21:05:49,558 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 21:05:49,560 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 21:05:49,560 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 21:05:49,561 - plugin_manager.py:96 - INFO - Plugin 'logging_plugin' registered.
2025-12-16 21:05:49,561 - plugin_manager.py:96 - INFO - Plugin 'rubric_guardrail' registered.
2025-12-16 21:06:05,853 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 21:06:13,830 - plugin_manager.py:96 - INFO - Plugin 'logging_plugin' registered.
2025-12-16 21:06:13,831 - plugin_manager.py:96 - INFO - Plugin 'rubric_guardrail' registered.
2025-12-16 21:06:13,834 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 21:06:20,102 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 21:06:23,190 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 21:06:25,843 - runners.py:432 - INFO - Running event compactor.
2025-12-16 21:06:25,848 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 21:06:30,963 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 21:06:32,709 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 21:06:32,710 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 21:06:32,710 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 21:06:32,718 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 21:06:32,725 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 21:06:43,857 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 21:06:49,885 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 21:06:52,491 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 21:07:02,558 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 21:07:15,229 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 21:07:16,856 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 21:07:30,192 - runners.py:432 - INFO - Running event compactor.
2025-12-16 21:18:12,984 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 21:18:22,021 - plugin_manager.py:96 - INFO - Plugin 'logging_plugin' registered.
2025-12-16 21:18:22,021 - plugin_manager.py:96 - INFO - Plugin 'rubric_guardrail' registered.
2025-12-16 21:18:22,025 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 21:18:28,778 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 21:18:33,094 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 21:18:39,230 - runners.py:432 - INFO - Running event compactor.
2025-12-16 21:18:39,234 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 21:18:46,904 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 21:18:52,330 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 21:18:52,330 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 21:18:52,331 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 21:18:52,332 - llm_provider.py:57 - INFO - Using OpenAI model: openai/gpt-5-mini
2025-12-16 21:18:52,341 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 21:18:52,357 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 21:19:01,688 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 21:19:02,901 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 21:19:11,849 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 21:19:14,151 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 21:19:18,859 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 21:19:26,654 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 21:19:27,416 - utils.py:3347 - INFO - 
LiteLLM completion() model= gpt-5-mini; provider = openai
2025-12-16 21:19:43,427 - runners.py:432 - INFO - Running event compactor.
