# ğŸ“ Smart Grading Assistant

> A multi-agent AI system for automated academic grading with human oversight

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://python.org)
[![Google ADK](https://img.shields.io/badge/Google%20ADK-0.1.0-green.svg)](https://github.com/google/adk)
[![Gemini](https://img.shields.io/badge/Gemini-2.5%20Flash-orange.svg)](https://ai.google.dev)

## ğŸ“‹ Table of Contents

- [Problem Statement](#-problem-statement)
- [Solution](#-solution)
- [Architecture](#-architecture)
- [Key Features](#-key-features)
- [Course Concepts Applied](#-course-concepts-applied)
- [Installation](#-installation)
- [Usage](#-usage)
- [Project Structure](#-project-structure)
- [Examples](#-examples)
- [Roadmap](#-roadmap)
- [Future Improvements](#-future-improvements)

---

## ğŸ¯ Problem Statement

Teachers and educators spend countless hours grading student submissions manually. This process is:

- **Time-consuming**: Hours spent on repetitive evaluation tasks
- **Inconsistent**: Grading quality varies based on fatigue and workload
- **Lacking feedback**: Students often receive minimal constructive feedback
- **Not scalable**: Difficult to maintain quality with large class sizes

## ğŸ’¡ Solution

**Smart Grading Assistant** is a multi-agent AI system that automates the grading process while maintaining human oversight for critical decisions. The system:

1. **Validates rubrics** before evaluation begins
2. **Evaluates submissions** against multiple criteria in parallel
3. **Aggregates scores** with detailed justifications
4. **Requests human approval** for edge cases (failing or exceptional grades)
5. **Generates constructive feedback** for students

### Why Agents?

Traditional automation struggles with the nuanced nature of academic evaluation. AI agents excel here because:

- **Reasoning**: Agents can understand context and apply judgment
- **Specialization**: Different agents focus on different criteria
- **Collaboration**: Agents work together like a grading committee
- **Oversight**: Human-in-the-loop ensures quality control

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SMART GRADING ASSISTANT                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  User Input: submission (text/code) + rubric                    â”‚
â”‚                          â†“                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚  â”‚     1. RubricValidatorAgent          â”‚ â† validate_rubric()   â”‚
â”‚  â”‚     Validates rubric structure        â”‚                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                          â†“                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚  â”‚     2. ParallelAgent                  â”‚                       â”‚
â”‚  â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚                       â”‚
â”‚  â”‚     â”‚ CriterionGrader1           â”‚   â”‚ â† grade_criterion()   â”‚
â”‚  â”‚     â”‚ CriterionGrader2           â”‚   â”‚                       â”‚
â”‚  â”‚     â”‚ CriterionGrader3           â”‚   â”‚                       â”‚
â”‚  â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                          â†“                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚  â”‚     3. AggregatorAgent               â”‚ â† calculate_score()   â”‚
â”‚  â”‚     Consolidates all grades           â”‚                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                          â†“                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚  â”‚     4. ApprovalAgent                  â”‚ â† Human-in-the-Loop  â”‚
â”‚  â”‚     (If score < 50% or > 90%)        â”‚                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                          â†“                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚  â”‚     5. FeedbackGeneratorAgent        â”‚                       â”‚
â”‚  â”‚     Creates constructive feedback     â”‚                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                          â†“                                       â”‚
â”‚  Output: Grade + Detailed Feedback + Justifications             â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ¨ Key Features

| Feature | Description |
|---------|-------------|
| ğŸ” **Rubric Validation** | Ensures rubrics are complete before evaluation |
| âš¡ **Parallel Grading** | Multiple criteria evaluated simultaneously |
| ğŸ§® **Smart Aggregation** | Calculates final scores with letter grades |
| ğŸ‘¤ **Human Oversight** | Teacher approval for edge cases |
| ğŸ’¬ **Rich Feedback** | Constructive, actionable student feedback |
| ğŸ’¾ **Persistent Sessions** | SQLite storage for grading history |
| ğŸ“Š **Observability** | Comprehensive logging for audit trails |

---

## ğŸ“š Course Concepts Applied

This capstone demonstrates **6+ key concepts** from the 5-Day AI Agents Intensive Course:

| # | Concept | Implementation | Course Day |
|---|---------|----------------|------------|
| 1 | **Multi-agent (Sequential)** | Validator â†’ Graders â†’ Aggregator â†’ Feedback | Day 1 |
| 2 | **Multi-agent (Parallel)** | Multiple criteria graders run simultaneously | Day 1 |
| 3 | **Custom Tools** | `validate_rubric()`, `grade_criterion()`, `calculate_score()` | Day 2 |
| 4 | **Human-in-the-Loop** | `request_confirmation` for edge case grades | Day 2 |
| 5 | **Sessions & Memory** | `DatabaseSessionService` for persistence | Day 3 |
| 6 | **Observability** | `LoggingPlugin` for audit trail | Day 4 |
| 7 | **Gemini Model** | Powered by Gemini 2.5 Flash | Bonus |

---

## ğŸš€ Installation

### Prerequisites

- Python 3.10+
- Google API Key (for Gemini)

### Setup

```bash
# Clone the repository
cd capstone

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Edit .env and add your GOOGLE_API_KEY
```

---

## ğŸ“– Usage

### Basic Usage

```bash
python agent.py
```

This runs a demo that:
1. Loads the Python code rubric
2. Evaluates the sample Fibonacci submission
3. Displays the grading results

### Programmatic Usage

```python
import asyncio
from agent import grade_submission

rubric = {
    "name": "My Rubric",
    "criteria": [
        {"name": "Quality", "max_score": 50, "description": "..."},
        {"name": "Completeness", "max_score": 50, "description": "..."}
    ]
}

submission = "Student's work here..."

result = asyncio.run(grade_submission(submission, rubric))
print(result)
```

### Expected Output

```
ğŸ“ SMART GRADING ASSISTANT - DEMO
============================================================

ğŸ“‹ Rubric: Python Code Evaluation Rubric
ğŸ“ Submission: Fibonacci Calculator

â³ Starting evaluation...

============================================================
ğŸ“Š EVALUATION RESULTS
============================================================

âœ… Rubric validated: 3 criteria, 100 total points

ğŸ“ Code Quality: 25/30
   Clean recursive implementation with good naming conventions...

ğŸ“ Functionality: 35/40
   Correctly calculates Fibonacci numbers, but O(2^n) complexity...

ğŸ“ Documentation: 28/30
   Good docstrings, clear comments explaining the logic...

ğŸ“Š Final Score: 88/100 (88%) - Grade: B

ğŸ’¬ Feedback:
   Great work on this Fibonacci implementation! Your code is clean
   and well-documented. Consider using memoization to improve
   performance for larger inputs...

============================================================
âœ… Session ID: grading_a1b2c3d4
============================================================
```

---

## ğŸ“ Project Structure

```
capstone/
â”œâ”€â”€ agent.py                    # Main entry point with all agents
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ validate_rubric.py      # Rubric validation tool
â”‚   â”œâ”€â”€ grade_criterion.py      # Criterion grading tool
â”‚   â””â”€â”€ calculate_score.py      # Score calculation tool
â”œâ”€â”€ agents/
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ rubrics/
â”‚   â”‚   â”œâ”€â”€ python_code_rubric.json
â”‚   â”‚   â””â”€â”€ essay_rubric.json
â”‚   â””â”€â”€ submissions/
â”‚       â”œâ”€â”€ sample_code.py
â”‚       â””â”€â”€ sample_essay.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ PLAN.md                     # Development plan
â””â”€â”€ README.md                   # This file
```

---

## ğŸ“ Examples

### Python Code Rubric

```json
{
    "name": "Python Code Evaluation Rubric",
    "criteria": [
        {
            "name": "Code Quality",
            "max_score": 30,
            "description": "Readability, naming, PEP 8 adherence"
        },
        {
            "name": "Functionality",
            "max_score": 40,
            "description": "Correctness, edge cases, bugs"
        },
        {
            "name": "Documentation",
            "max_score": 30,
            "description": "Docstrings, comments, clarity"
        }
    ]
}
```

### Essay Rubric

```json
{
    "name": "Academic Essay Evaluation Rubric",
    "criteria": [
        {
            "name": "Thesis and Argumentation",
            "max_score": 35,
            "description": "Clarity of thesis, argument development"
        },
        {
            "name": "Organization",
            "max_score": 25,
            "description": "Structure, transitions, flow"
        },
        {
            "name": "Language",
            "max_score": 25,
            "description": "Grammar, style, word choice"
        },
        {
            "name": "Critical Thinking",
            "max_score": 15,
            "description": "Depth of analysis, originality"
        }
    ]
}
```

---

## ğŸ—ºï¸ Roadmap

- **Phase 1 â€“ Core Grading (MVP)**  
  - [x] Implementar pipeline multi-agente para avaliaÃ§Ã£o de submissÃµes usando rÃºbricas.
  - [x] Validar estrutura de rÃºbricas e calcular notas finais com feedback detalhado.

- **Phase 2 â€“ Rubric Assistant com RAG (prÃ³ximo passo)**  
  - [ ] Criar um *Rubric Assistant* baseado em RAG para apoiar professores na criaÃ§Ã£o e revisÃ£o de rÃºbricas:
    - Indexar rÃºbricas existentes e exemplos de avaliaÃ§Ãµes bem-sucedidas em uma base de conhecimento.
    - Usar RAG para recuperar trechos relevantes de rÃºbricas, orientaÃ§Ãµes pedagÃ³gicas e exemplos de critÃ©rios.
    - Permitir que o professor faÃ§a perguntas como "como melhorar este critÃ©rio?" ou "exemplo de rubrica para projeto de cÃ³digo Python".

- **Phase 3 â€“ UX & Deployment**  
  - [ ] Adicionar frontend em Streamlit para upload de rÃºbricas e submissÃµes, visualizaÃ§Ã£o de notas e feedback.
  - [ ] Preparar o projeto para deploy em ambientes como Cloud Run / Agent Engine.

## ğŸ”® Future Improvements

- [ ] **Streamlit Frontend**: Web interface for easy interaction
- [ ] **Batch Grading**: Process multiple submissions at once
- [ ] **Custom Rubric Builder**: UI for creating rubrics
- [ ] **Analytics Dashboard**: Track grading patterns and statistics
- [ ] **Export Options**: PDF reports, CSV exports
- [ ] **Cloud Deployment**: Deploy on Google Cloud Run

---

## ğŸ™ Acknowledgments

This project was created as part of the **5-Day AI Agents Intensive Course with Google** on Kaggle.

- [Course Page](https://www.kaggle.com/learn-guide/5-day-agents)
- [YouTube Playlist](https://www.youtube.com/playlist?list=PLqFaTIg4myu9r7uRoNfbJhHUbLp-1t1YE)

---

## ğŸ“„ License

MIT License - See [LICENSE](../LICENSE) for details.

---

**Built with â¤ï¸ using Google ADK and Gemini**
